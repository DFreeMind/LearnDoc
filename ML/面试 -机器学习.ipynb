{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 机器学习面试"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [BAT机器学习面试1000题系列（第1~325题）](https://blog.csdn.net/v_july_v/article/details/78121924)\n",
    "- [深度学习岗位面试问题整理笔记](https://zhuanlan.zhihu.com/p/25005808)\n",
    "- [面试笔试整理3：深度学习机器学习面试问题准备（必会）](https://blog.csdn.net/woaidapaopao/article/details/77806273)\n",
    "- [面试笔试整理4：机器学习面试问题准备（进阶）](https://blog.csdn.net/woaidapaopao/article/details/77869840)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 常见问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [机器学习常见面试问题（一）](https://blog.csdn.net/timcompp/article/details/62237986)\n",
    "- [机器学习面试问题集（2018-3-13更新）](https://blog.csdn.net/u011239443/article/details/76360294)\n",
    "- [如果你是面试官，你怎么去判断一个面试者的深度学习水平？](https://www.zhihu.com/question/41233373/answer/145404190)\n",
    "- [45 Questions to test a data scientist on basics of Deep Learning (along with solution)](https://www.analyticsvidhya.com/blog/2017/01/must-know-questions-deep-learning/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**算法**\n",
    "\n",
    "- [机器学习&数据挖掘笔记_16（常见面试之机器学习算法思想简单梳理)](http://www.cnblogs.com/tornadomeet/p/3395593.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [How to handle Imbalanced Classification Problems in machine learning?](https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 习题集\n",
    "- [机器学习习题集](https://blog.csdn.net/v_july_v/article/details/78121924)\n",
    "- [#12 机器学习能力自测题—看看你的机器学习知识能打几分？不容错过的机器学习试题与术语](http://nooverfit.com/wp/12-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%83%BD%E5%8A%9B%E8%87%AA%E6%B5%8B%E9%A2%98-%E7%9C%8B%E7%9C%8B%E4%BD%A0%E7%9A%84%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E8%83%BD%E6%89%93/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 常见模型\n",
    " \n",
    "- [机器学习参数模型与非参数模型](https://www.deeplearn.me/1854.html)\n",
    "![img](https://ws1.sinaimg.cn/large/69d4185bly1fqurzz8m6dj20we0kpjvq.jpg)\n",
    "\n",
    "### SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [支持向量机通俗导论（理解SVM的三层境界）](https://blog.csdn.net/v_july_v/article/details/7624837)\n",
    "- [机器学习——SVM详解（标准形式，对偶形式，Kernel及Soft Margin）](http://www.cnblogs.com/little-YTMM/p/5547642.html)\n",
    "- [A glimpse of Support Vector Machine](http://www.cnblogs.com/massquantity/p/7580688.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 回归( Regression）\n",
    "- [Logistic Regression 的前世今生（理论篇）](https://blog.csdn.net/cyh_24/article/details/50359055)\n",
    "- [机器学习算法与Python实践之（七）逻辑回归（Logistic Regression](https://blog.csdn.net/zouxy09/article/details/20319673)\n",
    "- [线性分类器和非线性分类器](https://blog.csdn.net/u014755493/article/details/70182532)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 聚类与分类\n",
    "- [从K近邻算法、距离度量谈到KD树、SIFT+BBF算法](https://blog.csdn.net/v_july_v/article/details/8203674)\n",
    "- [Kmeans、Kmeans++和KNN算法比较](https://blog.csdn.net/chlele0105/article/details/12997391)\n",
    "- [k-means++和k-means||](https://blog.csdn.net/u012102306/article/details/52212870)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 集成学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [集成学习总结](https://xijunlee.github.io/2017/06/03/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/)\n",
    "- [**GBDT（MART） 迭代决策树入门教程 | 简介**](https://blog.csdn.net/w28971023/article/details/8240756)\n",
    "- [scikit-learn 梯度提升树(GBDT)调参小结](http://www.cnblogs.com/pinard/p/6143927.html)\n",
    "- [scikit-learn集成学习module-sklearn.ensemble](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.ensemble)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Adaboost 算法的原理与推导](https://blog.csdn.net/v_july_v/article/details/40718799)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 概率图模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [如何用简单易懂的例子解释条件随机场（CRF）模型？它和HMM有什么区别？](https://www.zhihu.com/question/35866596)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [从贝叶斯方法谈到贝叶斯网络](https://blog.csdn.net/v_july_v/article/details/40984699)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 神经网络\n",
    "### 前沿\n",
    "- [The Last 5 Years In Deep Learning](https://adeshpande3.github.io/)\n",
    "- [深度学习在计算机视觉领域的前沿进展](https://zhuanlan.zhihu.com/p/24699780)\n",
    "- [浅析 Hinton 最近提出的 Capsule 计划](https://zhuanlan.zhihu.com/p/29435406)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 卷积神经网络\n",
    "- [CNN笔记：通俗理解卷积神经网络](https://blog.csdn.net/v_july_v/article/details/51812459)\n",
    "- [A Beginner's Guide To Understanding Convolutional Neural Networks](https://adeshpande3.github.io/adeshpande3.github.io/A-Beginner's-Guide-To-Understanding-Convolutional-Neural-Networks/)\n",
    "- [一文详解神经网络 BP 算法原理及 Python 实现](https://www.leiphone.com/news/201705/TMsNCqjpOIfN3Bjr.html)\n",
    "- [BP 算法之一种直观的解释](https://www.cnblogs.com/daniel-D/archive/2013/06/03/3116278.html)\n",
    "\n",
    "**卷积直观解释**\n",
    "- [如何通俗易懂地解释卷积？](https://www.zhihu.com/question/22298352)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [神经网络激励函数的作用是什么？有没有形象的解释？](https://www.zhihu.com/question/22334626)\n",
    "- [通俗理解神经网络之激励函数(Activation Function)](https://blog.csdn.net/hyman_yx/article/details/51789186)\n",
    "- [深度学习: Batch Normalization (归一化)](https://blog.csdn.net/JNingWei/article/details/78866591)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 层解析\n",
    "- [为什么很多做人脸的Paper会最后加入一个Local Connected Conv？](https://blog.csdn.net/u014365862/article/details/77795902)\n",
    "- [Understanding Locally Connected Layers In Convolutional Neural Networks](https://prateekvjoshi.com/2016/04/12/understanding-locally-connected-layers-in-convolutional-neural-networks/)\n",
    "- [DeepFace--Facebook的人脸识别](https://blog.csdn.net/stdcoutzyx/article/details/46776415)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 其他神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [循环神经网络(RNN, Recurrent Neural Networks)介绍](https://blog.csdn.net/heyongluoyao8/article/details/48636251)\n",
    "- [深度学习——循环神经网络/递归神经网络（RNN）及其改进的长短时记忆网络（LSTM）](https://blog.csdn.net/loveliuzz/article/details/79156025)\n",
    "- [Understanding LSTM Networks](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 优化\n",
    "- [神经网络训练中的梯度消失与梯度爆炸](https://zhuanlan.zhihu.com/p/25631496)\n",
    "- [如何解决梯度消失和梯度膨胀？](https://www.zhihu.com/question/38102762)\n",
    "- [批标准化 (Batch Normalization)](https://morvanzhou.github.io/tutorials/machine-learning/ML-intro/3-08-batch-normalization/)\n",
    "- [cs231n学习笔记-激活函数-BN-参数优化](https://blog.csdn.net/myarrow/article/details/51848285)\n",
    "\n",
    "**卷积优化**\n",
    "\n",
    "- [卷积Im2Col - 加速卷积操作](https://blog.csdn.net/u013498583/article/details/79414225)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型\n",
    "- [Google Xception Network](https://blog.csdn.net/shuzfan/article/details/77129716)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 语义"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [topic model (LSA、PLSA、LDA)](https://blog.csdn.net/lmm6895071/article/details/74999129)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 优化等\n",
    "- [概览深度学习中的五大正则化方法和七大优化策略](https://zhuanlan.zhihu.com/p/32194445)\n",
    "- [正则化方法：L1和L2 regularization、数据集扩增、dropout](https://blog.csdn.net/u012162613/article/details/44261657)\n",
    "- [为什么一些机器学习模型需要对数据进行归一化](http://www.cnblogs.com/LBSer/p/4440590.html)\n",
    "- [机器学习中常见的最优化算法](https://blog.csdn.net/wtq1993/article/details/51607040)\n",
    "- [机器学习中的范数规则化之（一）L0、L1与L2范数](https://blog.csdn.net/zouxy09/article/details/24971995/)\n",
    "\n",
    "### 特征工程\n",
    "- [连续特征的离散化：在什么情况下将连续的特征离散化之后可以获得更好的效果？](https://www.zhihu.com/question/31989952)\n",
    "- [对于特征离散化，特征交叉，连续特征离散化非常经典的解释](https://blog.csdn.net/lujiandong1/article/details/52412123)\n",
    "\n",
    "**降维**\n",
    "- [PCA的数学原理](http://blog.codinglabs.org/articles/pca-tutorial.html)\n",
    "- [t-SNE完整笔记](http://www.datakit.cn/blog/2017/02/05/t_sne_full.html)\n",
    "- [淺談降維方法中的 PCA 與 t-SNE](https://medium.com/d-d-mag/%E6%B7%BA%E8%AB%87%E5%85%A9%E7%A8%AE%E9%99%8D%E7%B6%AD%E6%96%B9%E6%B3%95-pca-%E8%88%87-t-sne-d4254916925b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 调参&性能\n",
    "- [你有哪些deep learning（rnn、cnn）调参的经验？](https://www.zhihu.com/question/41631631/answer/94816420)\n",
    "- [机器学习系列(20)_机器学习性能改善备忘单](https://blog.csdn.net/han_xiaoyang/article/details/53453145)\n",
    "- [机器学习系列(10)_如何提高深度学习(和机器学习)的性能](https://blog.csdn.net/han_xiaoyang/article/details/52654879)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 可视化\n",
    "- [资源 | 从ReLU到Sinc，26种神经网络激活函数可视化](https://mp.weixin.qq.com/s/7DgiXCNBS5vb07WIKTFYRQ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据预处理\n",
    "- [机器学习（七）白化whitening](https://blog.csdn.net/hjimce/article/details/50864602)\n",
    "- [数据降维与可视化——t-SNE](https://blog.csdn.net/hustqb/article/details/78144384)\n",
    "- [t-sne数据可视化算法的作用是啥？为了降维还是认识数据？](https://www.zhihu.com/question/52022955)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 算法比较"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [机器学习算法集锦：从贝叶斯到深度学习及各自优缺点](https://zhuanlan.zhihu.com/p/25327755)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 评估"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [机器学习-损失函数](http://www.csuldw.com/2016/03/26/2016-03-26-loss-function/)\n",
    "- [Python Numpy计算各类距离](https://blog.csdn.net/qq_19707521/article/details/78479532)\n",
    "- [机器学习笔记之KNN算法](http://sccsec.com/2017/04/10/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%B9%8BKNN%E7%AE%97%E6%B3%95/)\n",
    "- [欧氏距离与马氏距离](https://blog.csdn.net/u010167269/article/details/51627338)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 编程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## python\n",
    "### 面试题\n",
    "- [15个重要Python面试题 测测你适不适合做Python？](http://nooverfit.com/wp/15%E4%B8%AA%E9%87%8D%E8%A6%81python%E9%9D%A2%E8%AF%95%E9%A2%98-%E6%B5%8B%E6%B5%8B%E4%BD%A0%E9%80%82%E4%B8%8D%E9%80%82%E5%90%88%E5%81%9Apython%EF%BC%9F/)\n",
    "- [2017 Python最新面试题及答案16道题](http://www.cnblogs.com/tom-gao/p/6645859.html)\n",
    "- [Python面试必须要看的15个问题](http://codingpy.com/article/essential-python-interview-questions/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基础知识\n",
    "- [Python 类的继承和多态](https://www.cnblogs.com/feeland/p/4419121.html)\n",
    "- [python中使用多继承问题和super()内置函数的使用](https://blog.csdn.net/helloxiaozhe/article/details/79384554)\n",
    "\n",
    "**类型**\n",
    "- [Python的函数参数传递：传值？引用？](http://winterttr.me/2015/10/24/python-passing-arguments-as-value-or-reference/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### python周边\n",
    "**多线程**\n",
    "- [Python的GIL是什么鬼，多线程性能究竟如何](http://cenalulu.github.io/python/gil-in-python/)\n",
    "\n",
    "**垃圾回收及其内存**\n",
    "- [Python垃圾回收机制详解](http://www.cnblogs.com/Xjng/p/5128269.html)\n",
    "- [python的内存管理机制](http://www.cnblogs.com/CBDoctor/p/3781078.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 算法\n",
    "- [教你如何迅速秒杀掉：99%的海量数据处理面试题](https://blog.csdn.net/v_july_v/article/details/7382693)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 应用案例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [机器学习算法应用场景实例六十则](http://lib.csdn.net/article/machinelearning/59329)\n",
    "- [机器学习算法快速选择](https://www.jianshu.com/p/9e31c156b092)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](https://ws1.sinaimg.cn/large/69d4185bgy1fq9y17s736j216j0ov17h.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数学\n",
    "- [流形学习（manifold learning）综述](https://blog.csdn.net/chl033/article/details/6107042)\n",
    "- [浅谈流形学习](http://blog.pluskid.org/?p=533)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**对偶问题**\n",
    "- [第 2 章 对偶线性规划](http://netedu.xauat.edu.cn/jpkc/netedu/jpkc/ycx/kcjy/kejian/pdf/02.pdf)\n",
    "- [对偶理论 - 百度百科](https://baike.baidu.com/item/%E5%AF%B9%E5%81%B6%E7%90%86%E8%AE%BA/9582786)\n",
    "\n",
    "**凸二次规划**\n",
    "\n",
    "- [机器学习&数据挖掘笔记_15（关于凸优化的一些简单概念）](http://www.cnblogs.com/tornadomeet/p/3300132.html)\n",
    "- [约束规划问题与凸二次规划](https://blog.csdn.net/philthinker/article/details/78510361)\n",
    "- [第五讲---线性规划与二次规划](http://see.xidian.edu.cn/faculty/plshui/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E5%9F%BA%E7%A1%80%E4%B8%8E%E5%AE%9E%E9%AA%8C%E8%AE%B2%E4%B9%89/%E7%AC%AC%E4%BA%94%E8%AE%B2---%E7%BA%BF%E6%80%A7%E8%A7%84%E5%88%92%E4%B8%8E%E4%BA%8C%E6%AC%A1%E8%A7%84%E5%88%92.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**极值求解**\n",
    "- [从最大似然到EM(最大期望算法)算法浅解](https://blog.csdn.net/zouxy09/article/details/8537620)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 概率论"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [先验分布、后验分布、似然估计这几个概念是什么意思，它们之间的关系是什么？](https://www.zhihu.com/question/24261751)\n",
    "- [一个例子搞清楚（先验分布/后验分布/似然估计)](https://blog.csdn.net/qq_23947237/article/details/78265026)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 高数\n",
    "- [机器学习中的数学(1)-回归(regression)、梯度下降(gradient descent)](http://www.cnblogs.com/LeftNotEasy/archive/2010/12/05/mathmatic_in_machine_learning_1_regression_and_gradient_descent.html)\n",
    "- [自动微分(Automatic Differentiation)简介](https://blog.csdn.net/aws3217150/article/details/70214422)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [机器学习和统计里面的auc怎么理解？](https://www.zhihu.com/question/39840928)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 线性代数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [如何通俗地讲解「仿射变换」这个概念？](https://www.zhihu.com/question/20666664)\n",
    "- [如何通俗的解释仿射变换？](https://www.matongxue.com/madocs/244.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 其他"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 补充视频"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [机器学习基础知识视频：矩阵、算法等](http://www.julyedu.com/video/play/18/323###)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 扫盲"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [一文读懂机器学习、数据科学、人工智能、深度学习和统计学之间的区别](https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650723678&idx=1&sn=5cb049e37427dd2b2a4e30e42bcc2fff&chksm=871b1120b06c983651bf92526cd8554225304200364d39cd18592fd8a6848d1f84cf80aeea22&scene=21#wechat_redirect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "304px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
