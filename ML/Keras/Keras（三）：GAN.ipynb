{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[NIPS 2016 Tutorial: Generative Adversarial Networks](https://arxiv.org/abs/1701.00160)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key intuition of GAN can be easily considered as analogous to art forgery, which is the process of creating works of art that are falsely credited to other, usually more famous, artists. GANs train two neural nets simultaneously, as shown in the next diagram. The generator G(Z) makes the forgery, and the discriminator D(Y) can judge how realistic the reproductions based on its observations of authentic pieces of arts and copies are. D(Y) takes an input, Y, (for instance, an image) and expresses a vote to judge how real the input is--in general, a value close to zero denotes real and a value close to one denotes forgery. G(Z) takes an input from a random noise, Z, and trains itself to fool D into thinking that whatever G(Z) produces is real. So, the goal of training the discriminator D(Y) is to maximize D(Y) for every image from the true data distribution, and to minimize D(Y) for every image not from the true data distribution. So, G and D play an opposite game; hence the name adversarial training. Note that we train G and D in an alternating manner, where each of their objectives is expressed as a loss function optimized via a gradient descent. The generative model learns how to forge more successfully, and the discriminative model learns how to recognize forgery more successfully. The discriminator network (usually a standard convolutional neural network) tries to classify whether an input image is real or generated. The important new idea is to backpropagate through both the discriminator and the generator to adjust the generator's parameters in such a way that the generator can learn how to fool the the discriminator for an increasing number of situations. At the end, the generator will learn how to produce forged images that are indistinguishable from real ones:\n",
    "![image](https://ws4.sinaimg.cn/large/69d4185bly1fyeo8qd5jtj20eo069dgb.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, GANs require finding the equilibrium in a game with two players. For effective learning it is required that if a player successfully moves downhill in a round of updates, the same update must move the other player downhill too. Think about it! If the forger learns how to fool the judge on every occasion, then the forger himself has nothing more to learn. Sometimes the two players eventually reach an equilibrium, but this is not always guaranteed and the two players can continue playing for a long time. An example of learning from both sides has been provided in the following graph:\n",
    "![image](https://wx4.sinaimg.cn/large/69d4185bly1fyeodrawfqj20mx0je3zz.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 深度卷积GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示意图如下：\n",
    "![image](https://ws1.sinaimg.cn/large/69d4185bly1fyeokzt9lyj20n20di40u.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上图在 keras 中可以表示成如下形式：\n",
    "```python\n",
    "def generator_model () :\n",
    "    model = Sequential()\n",
    "    model.add(Dense (input_dim=100, output_dim=1024) )\n",
    "    model.add(Activation( 'tanh') )\n",
    "    model.add(Dense (128*7*7) )\n",
    "    model.add(BatchNormalization() )\n",
    "    model.add(Activation( 'tanh') )\n",
    "    model.add(Reshape( (128, 7, 7), input_shape= (128*7*7,)))\n",
    "    model.add(UpSampling2D (size=(2, 2)) )\n",
    "    model.add(Convolution2D(64, 5, 5, padding=' same') )\n",
    "    model.add(Activation( 'tanh') )\n",
    "    model.add(UpSampling2D (size=(2, 2)) )\n",
    "    model.add(Convolution2D(1, 5, 5, padding=' same' ) )\n",
    "    model.add(Activation( 'tanh') )\n",
    "    return model\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "判别模型可以表示成如下形式：\n",
    "```python\n",
    "def discriminator_ model () :\n",
    "    model = Sequential ()\n",
    "    model.add(Convolution2D(64, 5, 5, padding='same' , input_shape=(1, 28, 28) ) )\n",
    "    model.add(Activation( 'tanh') )\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)) )\n",
    "    model.add(Convolution2D(128, 5, 5))\n",
    "    model.add(Activation( 'tanh') )\n",
    "    model.add(MaxPooling2D (pool_size=(2, 2) ) )\n",
    "    model.add(Flatten() )\n",
    "    model.add(Dense (1024) )\n",
    "    model.add(Activation( 'tanh') )\n",
    "    model.add(Dense (1) )\n",
    "    model.add(Activation(' sigmoid') )\n",
    "    return model\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 生成 MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用 keras-adversaial 时要注意版本，最好使用 keras 2.1.2，或者 keras1.x ，要不会出现不可预知的错误。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "# This line allows mpl to run with no DISPLAY defined\n",
    "mpl.use('Agg')\n",
    "\n",
    "from keras.layers import Flatten, Dropout, LeakyReLU, Input, Activation\n",
    "from keras.models import Model\n",
    "from keras.layers.convolutional import UpSampling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.datasets import mnist\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "\n",
    "from keras_adversarial.legacy import Dense, BatchNormalization, Convolution2D\n",
    "from keras_adversarial.image_grid_callback import ImageGridCallback\n",
    "from keras_adversarial import AdversarialModel, simple_gan, gan_targets\n",
    "from keras_adversarial import AdversarialOptimizerSimultaneous, normal_latent_sampling\n",
    "from image_utils import dim_ordering_fix, dim_ordering_input\n",
    "from image_utils import dim_ordering_reshape, dim_ordering_unfix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leaky_relu(x):\n",
    "    return K.relu(x, 0.2)\n",
    "\n",
    "\n",
    "def model_generator():\n",
    "    nch = 256\n",
    "    g_input = Input(shape=[100])\n",
    "    H = Dense(nch * 14 * 14)(g_input)\n",
    "    H = BatchNormalization(mode=2)(H)\n",
    "    H = Activation('relu')(H)\n",
    "    H = dim_ordering_reshape(nch, 14)(H)\n",
    "    H = UpSampling2D(size=(2, 2))(H)\n",
    "    H = Convolution2D(int(nch / 2), 3, 3, border_mode='same')(H)\n",
    "    H = BatchNormalization(mode=2, axis=1)(H)\n",
    "    H = Activation('relu')(H)\n",
    "    H = Convolution2D(int(nch / 4), 3, 3, border_mode='same')(H)\n",
    "    H = BatchNormalization(mode=2, axis=1)(H)\n",
    "    H = Activation('relu')(H)\n",
    "    H = Convolution2D(1, 1, 1, border_mode='same')(H)\n",
    "    g_V = Activation('sigmoid')(H)\n",
    "    return Model(g_input, g_V)\n",
    "\n",
    "\n",
    "def model_discriminator(input_shape=(1, 28, 28), dropout_rate=0.5):\n",
    "    d_input = dim_ordering_input(input_shape, name=\"input_x\")\n",
    "    nch = 512\n",
    "    # nch = 128\n",
    "    H = Convolution2D(int(nch / 2), 5, 5, subsample=(2, 2), \n",
    "                      border_mode='same', activation='relu')(d_input)\n",
    "    H = LeakyReLU(0.2)(H)\n",
    "    H = Dropout(dropout_rate)(H)\n",
    "    H = Convolution2D(nch, 5, 5, subsample=(2, 2), \n",
    "                      border_mode='same', activation='relu')(H)\n",
    "    H = LeakyReLU(0.2)(H)\n",
    "    H = Dropout(dropout_rate)(H)\n",
    "    H = Flatten()(H)\n",
    "    H = Dense(int(nch / 2))(H)\n",
    "    H = LeakyReLU(0.2)(H)\n",
    "    H = Dropout(dropout_rate)(H)\n",
    "    d_V = Dense(1, activation='sigmoid')(H)\n",
    "    return Model(d_input, d_V)\n",
    "\n",
    "\n",
    "def mnist_process(x):\n",
    "    x = x.astype(np.float32) / 255.0\n",
    "    return x\n",
    "\n",
    "\n",
    "def mnist_data():\n",
    "    (xtrain, ytrain), (xtest, ytest) = mnist.load_data()\n",
    "    return mnist_process(xtrain), mnist_process(xtest)\n",
    "\n",
    "\n",
    "def generator_sampler(latent_dim, generator):\n",
    "    zsamples = np.random.normal(size=(10 * 10, latent_dim))\n",
    "    gen = dim_ordering_unfix(generator.predict(zsamples))\n",
    "    return gen.reshape((10, 10, 28, 28))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # z \\in R^100\n",
    "    latent_dim = 100\n",
    "    # x \\in R^{28x28}\n",
    "    input_shape = (1, 28, 28)\n",
    "\n",
    "    # generator (z -> x)\n",
    "    generator = model_generator()\n",
    "    # discriminator (x -> y)\n",
    "    discriminator = model_discriminator(input_shape=input_shape)\n",
    "    # gan (x - > yfake, yreal), z generated on GPU\n",
    "    gan = simple_gan(generator, discriminator, normal_latent_sampling((latent_dim,)))\n",
    "\n",
    "    # print summary of models\n",
    "    generator.summary()\n",
    "    discriminator.summary()\n",
    "    gan.summary()\n",
    "\n",
    "    # build adversarial model\n",
    "    model = AdversarialModel(base_model=gan,\n",
    "                             player_params=[generator.trainable_weights, \n",
    "                                            discriminator.trainable_weights],\n",
    "                             player_names=[\"generator\", \"discriminator\"])\n",
    "    model.adversarial_compile(adversarial_optimizer=AdversarialOptimizerSimultaneous(),\n",
    "                              player_optimizers=[Adam(1e-4, decay=1e-4), \n",
    "                                                 Adam(1e-3, decay=1e-4)],\n",
    "                              loss='binary_crossentropy')\n",
    "\n",
    "    # train model\n",
    "    generator_cb = ImageGridCallback(\"./models/gan/epoch-{:03d}.png\",\n",
    "                                     generator_sampler(latent_dim, generator))\n",
    "\n",
    "    xtrain, xtest = mnist_data()\n",
    "    xtrain = dim_ordering_fix(xtrain.reshape((-1, 1, 28, 28)))\n",
    "    xtest = dim_ordering_fix(xtest.reshape((-1, 1, 28, 28)))\n",
    "    y = gan_targets(xtrain.shape[0])\n",
    "    ytest = gan_targets(xtest.shape[0])\n",
    "    history = model.fit(x=xtrain, y=y, validation_data=(xtest, ytest), \n",
    "                        callbacks=[generator_cb], nb_epoch=100,\n",
    "                        batch_size=32)\n",
    "    df = pd.DataFrame(history.history)\n",
    "    df.to_csv(\"./models/gan/history.csv\")\n",
    "\n",
    "    generator.save(\"./models/gan/generator.h5\")\n",
    "    discriminator.save(\"./models/gan/discriminator.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 生成 CIFAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "# This line allows mpl to run with no DISPLAY defined\n",
    "mpl.use('Agg')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from keras.layers import Reshape, Flatten, LeakyReLU, Activation\n",
    "from keras.layers.convolutional import UpSampling2D, MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras_adversarial.image_grid_callback import ImageGridCallback\n",
    "\n",
    "from keras_adversarial import AdversarialModel, simple_gan, gan_targets\n",
    "from keras_adversarial import AdversarialOptimizerSimultaneous, normal_latent_sampling\n",
    "from keras_adversarial.legacy import Dense, BatchNormalization, fit, \n",
    "from keras_adversarial.legacy import l1l2, Convolution2D, AveragePooling2D\n",
    "import keras.backend as K\n",
    "from cifar10_utils import cifar10_data\n",
    "from image_utils import dim_ordering_fix, dim_ordering_unfix, dim_ordering_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_generator():\n",
    "    model = Sequential()\n",
    "    nch = 256\n",
    "    reg = lambda: l1l2(l1=1e-7, l2=1e-7)\n",
    "    h = 5\n",
    "    model.add(Dense(nch * 4 * 4, input_dim=100, W_regularizer=reg()))\n",
    "    model.add(BatchNormalization(mode=0))\n",
    "    model.add(Reshape(dim_ordering_shape((nch, 4, 4))))\n",
    "    model.add(Convolution2D(int(nch / 2), h, h, border_mode='same', W_regularizer=reg()))\n",
    "    model.add(BatchNormalization(mode=0, axis=1))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Convolution2D(int(nch / 2), h, h, border_mode='same', W_regularizer=reg()))\n",
    "    model.add(BatchNormalization(mode=0, axis=1))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Convolution2D(int(nch / 4), h, h, border_mode='same', W_regularizer=reg()))\n",
    "    model.add(BatchNormalization(mode=0, axis=1))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Convolution2D(3, h, h, border_mode='same', W_regularizer=reg()))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    return model\n",
    "\n",
    "\n",
    "def model_discriminator():\n",
    "    nch = 256\n",
    "    h = 5\n",
    "    reg = lambda: l1l2(l1=1e-7, l2=1e-7)\n",
    "\n",
    "    c1 = Convolution2D(int(nch / 4), h, h, border_mode='same', W_regularizer=reg(),\n",
    "                       input_shape=dim_ordering_shape((3, 32, 32)))\n",
    "    c2 = Convolution2D(int(nch / 2), h, h, border_mode='same', W_regularizer=reg())\n",
    "    c3 = Convolution2D(nch, h, h, border_mode='same', W_regularizer=reg())\n",
    "    c4 = Convolution2D(1, h, h, border_mode='same', W_regularizer=reg())\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(c1)\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(c2)\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(c3)\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(c4)\n",
    "    model.add(AveragePooling2D(pool_size=(4, 4), border_mode='valid'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Activation('sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def example_gan(adversarial_optimizer, path, opt_g, opt_d, nb_epoch, generator, \n",
    "                discriminator, latent_dim,\n",
    "                targets=gan_targets, loss='binary_crossentropy'):\n",
    "    csvpath = os.path.join(path, \"history.csv\")\n",
    "    if os.path.exists(csvpath):\n",
    "        print(\"Already exists: {}\".format(csvpath))\n",
    "        return\n",
    "\n",
    "    print(\"Training: {}\".format(csvpath))\n",
    "    # gan (x - > yfake, yreal), z is gaussian generated on GPU\n",
    "    # can also experiment with uniform_latent_sampling\n",
    "    generator.summary()\n",
    "    discriminator.summary()\n",
    "    gan = simple_gan(generator=generator,\n",
    "                     discriminator=discriminator,\n",
    "                     latent_sampling=normal_latent_sampling((latent_dim,)))\n",
    "\n",
    "    # build adversarial model\n",
    "    model = AdversarialModel(base_model=gan,\n",
    "                             player_params=[generator.trainable_weights, \n",
    "                                            discriminator.trainable_weights],\n",
    "                             player_names=[\"generator\", \"discriminator\"])\n",
    "    model.adversarial_compile(adversarial_optimizer=adversarial_optimizer,\n",
    "                              player_optimizers=[opt_g, opt_d],\n",
    "                              loss=loss)\n",
    "\n",
    "    # create callback to generate images\n",
    "    zsamples = np.random.normal(size=(10 * 10, latent_dim))\n",
    "\n",
    "    def generator_sampler():\n",
    "        xpred = dim_ordering_unfix(generator.predict(zsamples)).transpose((0, 2, 3, 1))\n",
    "        return xpred.reshape((10, 10) + xpred.shape[1:])\n",
    "\n",
    "    generator_cb = ImageGridCallback(os.path.join(path, \"epoch-{:03d}.png\"), \n",
    "                                     generator_sampler, cmap=None)\n",
    "\n",
    "    # train model\n",
    "    xtrain, xtest = cifar10_data()\n",
    "    y = targets(xtrain.shape[0])\n",
    "    ytest = targets(xtest.shape[0])\n",
    "    callbacks = [generator_cb]\n",
    "    if K.backend() == \"tensorflow\":\n",
    "        callbacks.append(\n",
    "            TensorBoard(log_dir=os.path.join(path, 'logs'), histogram_freq=0, \n",
    "                        write_graph=True, write_images=True))\n",
    "    history = fit(model, x=xtrain, y=y, validation_data=(xtest, ytest),\n",
    "                  callbacks=callbacks, nb_epoch=nb_epoch,\n",
    "                  batch_size=32)\n",
    "\n",
    "    # save history to CSV\n",
    "    df = pd.DataFrame(history.history)\n",
    "    df.to_csv(csvpath)\n",
    "\n",
    "    # save models\n",
    "    generator.save(os.path.join(path, \"generator.h5\"))\n",
    "    discriminator.save(os.path.join(path, \"discriminator.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # z \\in R^100\n",
    "    latent_dim = 100\n",
    "    # x \\in R^{28x28}\n",
    "    # generator (z -> x)\n",
    "    generator = model_generator()\n",
    "    # discriminator (x -> y)\n",
    "    discriminator = model_discriminator()\n",
    "    example_gan(AdversarialOptimizerSimultaneous(), \"output/gan-cifar10\",\n",
    "                opt_g=Adam(1e-4, decay=1e-5),\n",
    "                opt_d=Adam(1e-3, decay=1e-5),\n",
    "                nb_epoch=100, generator=generator, discriminator=discriminator,\n",
    "                latent_dim=latent_dim)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WaveNet 音频生成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "生成的关键是膨胀卷积。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
