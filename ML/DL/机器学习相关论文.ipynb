{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 机器学习相关论文"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 概括性\n",
    "- [https://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf](https://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数学"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Automatic Differentiation in Machine Learning: a Survey](https://arxiv.org/pdf/1502.05767.pdf)\n",
    "- [Understanding the difficulty of training deep feedforward neural networks](http://211.136.65.146/cache/jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf?ich_args2=113-27164102052693_d608199944e4977f8efe1c7a2f489f05_10001002_9c89672ed1cbf1d99e3d518939a83798_fbe02d341db3f929aa014e7e1609c20b)\n",
    "\n",
    "- [What Every Computer Scientist Should Know About Floating-Point Arithmetic](https://docs.oracle.com/cd/E19957-01/806-3568/ncg_goldberg.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 优化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift](https://arxiv.org/pdf/1502.03167.pdf)\n",
    "    - [How Does Batch Normalization Help Optimization? (No, It Is Not About Internal Covariate Shift)](https://arxiv.org/pdf/1805.11604.pdf)\n",
    "- [Dropout: A Simple Way to Prevent Neural Networks from Overfitting](http://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf)\n",
    "\n",
    "- [Large Scale Distributed Deep Networks](https://ai.google/research/pubs/pub40565)\n",
    "- [Fast large-scale optimization by unifying stochastic gradient and quasi-Newton methods](https://arxiv.org/pdf/1311.2115.pdf)\n",
    "\n",
    "**梯度更新**\n",
    "- [Adaptive Subgradient Methods for Online Learning and Stochastic Optimization](http://jmlr.org/papers/v12/duchi11a.html)\n",
    "- [Neural Networks for Machine Learning](http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf)\n",
    "- [ADAM: A METHOD FOR STOCHASTIC OPTIMIZATION](https://arxiv.org/pdf/1412.6980.pdf)\n",
    "- [Stochastic Gradient Descent Tricks](https://www.microsoft.com/en-us/research/wp-content/uploads/2012/01/tricks-2012.pdf)\n",
    "- [Efficient BackProp](http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf)\n",
    "- [Practical Recommendations for Gradient-Based Training of Deep Architectures](https://arxiv.org/pdf/1206.5533v2.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - [Deep Learning using Linear Support Vector Machines](https://arxiv.org/pdf/1306.0239.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Network In Network](https://arxiv.org/pdf/1312.4400.pdf)\n",
    "- [膨胀卷积 - MULTI-SCALE CONTEXT AGGREGATION BY DILATED CONVOLUTIONS](https://arxiv.org/pdf/1511.07122.pdf)\n",
    "    - [如何理解空洞卷积（dilated convolution）？](https://www.zhihu.com/question/54149221)\n",
    "    - [Rethinking Atrous Convolution for Semantic Image Segmentation](https://arxiv.org/pdf/1706.05587.pdf)\n",
    "    - [Understanding Convolution for Semantic Segmentation](https://arxiv.org/pdf/1702.08502.pdf)\n",
    "    - [CNN 中千奇百怪的卷积方式大汇总](https://www.leiphone.com/news/201709/AzBc9Sg44fs57hyY.html)\n",
    "    - [变形卷积核、可分离卷积？卷积神经网络中十大拍案叫绝的操作](https://www.leiphone.com/news/201708/0rQBSwPO62IBhRxV.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **LeNet**\n",
    "- [Gradiant-Based Learning Applied to Document Recognition](http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf)\n",
    "\n",
    "### **AlexNet**\n",
    "- [4824-imagenet-classification-with-deep-convolutional-neural-networks](http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks)\n",
    "    - [DL:CNN-ImageNet Classification with Deep Convolution Neural Networks](https://blog.csdn.net/oMengLiShuiXiang1234/article/details/50903356)\n",
    "  \n",
    "  **饱和与非饱和**\n",
    "    - [什么是non-saturating neurons非饱和神经元？](https://www.zhihu.com/question/264163033/answer/277468264)\n",
    "    - [What does the term saturating nonlinearities mean?](https://stats.stackexchange.com/questions/174295/what-does-the-term-saturating-nonlinearities-mean)\n",
    "    \n",
    "  ** LRN **\n",
    "    - [深度学习的局部响应归一化LRN(Local Response Normalization)理解](https://blog.csdn.net/yangdashi888/article/details/77918311)\n",
    "    - [【深度学习技术】LRN 局部响应归一化](https://blog.csdn.net/hduxiejun/article/details/70570086) 但在论文《[Very Deep Convolutional Networks for Large-Scale Visual Recognition](http://www.robots.ox.ac.uk/~vgg/research/very_deep/)》也就是 VGGNet 中提到 LRN 其实并没有起到什么作用。\n",
    "    \n",
    "  **OverLapping Pooling**\n",
    "    - [Why do training models with overlapping pooling make it harder to overfit CNNs? (in Krizhevsky 2012)](https://www.quora.com/Why-do-training-models-with-overlapping-pooling-make-it-harder-to-overfit-CNNs-in-Krizhevsky-2012)\n",
    "    - [池化方法总结（Pooling）](https://blog.csdn.net/danieljianfeng/article/details/42433475)\n",
    "    \n",
    "  **第一层输出神经元个数的问题**\n",
    "    - [How does Krizhevsky's '12 CNN get 253,440 neurons in the first layer?](https://stats.stackexchange.com/questions/132897/how-does-krizhevskys-12-cnn-get-253-440-neurons-in-the-first-layer)\n",
    "    - [the number of neurons in AlexNet](https://stackoverflow.com/questions/36733636/the-number-of-neurons-in-alexnet)\n",
    "    - [A Walk-through of AlexNet](https://medium.com/@smallfishbigsea/a-walk-through-of-alexnet-6cbd137a5637)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **ZFNet**\n",
    "- [Visualizing and Understanding Convolutional Networks](https://arxiv.org/abs/1311.2901)\n",
    "  \n",
    "  **涉及论文**\n",
    "    - [Multi-column Deep Neural Networks for Image Classification](https://arxiv.org/pdf/1202.2745.pdf)\n",
    "    - [Adaptive Deconvolutional Networks for Mid and High Level Feature Learning](http://www.matthewzeiler.com/wp-content/uploads/2017/07/iccv2011.pdf) Deconvnet 网络\n",
    "    \n",
    "  **相关解读**\n",
    "    - [Deep Visualization:可视化并理解CNN](https://zhuanlan.zhihu.com/p/24833574)\n",
    "    - [Concepts and Tricks In CNN(长期更新)](http://blog.cvmarcher.cn/posts/2015/05/17/cnn-trick/) 感受视野、坐标映射、卷积与全连接。\n",
    "    - [论文笔记 Visualizing and Understanding Convolutional Networks](https://www.cnblogs.com/everyday-haoguo/p/Note-Visualize.html) 给出了自己的总结\n",
    "    \n",
    "  **Deconvnet**\n",
    "    - [如何理解深度学习中的deconvolution networks？](https://www.zhihu.com/question/43609045/answer/120266511)\n",
    "    - [A guide to convolution arithmetic for deep learning](https://arxiv.org/abs/1603.07285)\n",
    "    - [Github - vdumoulin/conv_arithmetic](https://github.com/vdumoulin/conv_arithmetic)\n",
    "    - [Toeplitz matrix (常数对角矩阵)与 Circulant matrix(循环常数对角矩阵)](https://blog.csdn.net/lanchunhui/article/details/72190213)\n",
    "    \n",
    "  **Sparse coding 稀疏编码**\n",
    "    - [CSDN - Sparse Coding](https://blog.csdn.net/qq_14975217/article/details/51679572)\n",
    "    - [在路上 - 关于Sparse Coding](http://zhangliliang.github.io/2015/02/01/about-sparse-coding/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **GoogLeNet & V1-4**\n",
    "- [Going Deeper with Convolutions](https://arxiv.org/abs/1409.4842)\n",
    "\n",
    "  **涉及论文**\n",
    "    - [【9】Visualizing and Understanding Convolutional Networks](https://arxiv.org/abs/1311.2901)\n",
    "    - [【6】RCNN-Rich feature hierarchiesfor accurate object detection and semantic segmentation](https://arxiv.org/abs/1311.2524) 目标检测（Object Detection）\n",
    "    - [【12】Network In Network](https://arxiv.org/pdf/1312.4400.pdf) Inception 名字的由来\n",
    "    - [Overfeat: Integrated recognition, localization and detection using convolutional networks](https://arxiv.org/abs/1312.6229) 增加网络的深度以及增加每一层的带下来提高网络准确性，本地化（Localization），目标检测（Object Detection）\n",
    "    - [Improving neural networks by preventing co-adaptation of feature detectors](https://arxiv.org/abs/1207.0580) 使用 Dropout 解决过拟合问题\n",
    "    - [Deep neural networks for object detection](https://papers.nips.cc/paper/5207-deep-neural-networks-for-object-detection.pdf) 目标检测（Object Detection）\n",
    "    - [【5】Scalable object detection using deep neural networks.](https://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Erhan_Scalable_Object_Detection_2014_CVPR_paper.pdf) 目标检测（Object Detection）\n",
    "    - [DeepPose: Human Pose Estimation via Deep Neural Networks](https://arxiv.org/abs/1312.4659) 人类姿态评估（Human Pose Estimation）\n",
    "    - [【15】Robust Object Recognition with Cortex-Like Mechanisms](https://www.academia.edu/4945078/Robust_Object_Recognition_with_Cortex-Like_Mechanisms) 多尺寸处理\n",
    "    - [【8】Some Improvements on Deep Convolutional Neural Network Based Image Classification 1312.5402](https://arxiv.org/abs/1312.5402)\n",
    "  \n",
    "  **相关解读**\n",
    "    - [【深度学习】论文导读：GoogLeNet模型，Inception结构网络简化(Going deeper with convolutions)](https://blog.csdn.net/mao_xiao_feng/article/details/53350798)\n",
    "    - [论文阅读笔记：GoogLeNet Inception 网络](https://blog.csdn.net/u010579901/article/details/79216565) 文中对 V1-4都有论述，主要参考了文中 Inception 结构中需要 padding 的资料。\n",
    "    - [GoogleNet :Going deeper with convolutions 论文阅读](https://blog.csdn.net/Yan_Joy/article/details/55052204) 对卷积核的论述较多\n",
    "    - [GoogLeNet系列解读](https://blog.csdn.net/shuzfan/article/details/50738394)\n",
    "    - [Going deeper with convolutions笔记](https://blog.csdn.net/u014114990/article/details/50370446) 有较为深入的解读\n",
    "    - [**16组-Going Deeper with Convolutions 阅读笔记**](https://www.jianshu.com/p/ae5c9a0db8b9) 解读较为全面，很多问题都有讲到\n",
    "    \n",
    "  **稀疏连接**\n",
    "    - [卷积神经网络(CNN)学习笔记1：基础入门](http://www.jeyzhang.com/cnn-learning-notes-1.html)\n",
    "    - [CNN学习笔记（1）稀疏连接和权值共享的理解](https://blog.csdn.net/tuyunbin1995/article/details/52888506)\n",
    "   \n",
    "  **相关问题**\n",
    "    - [1×1的卷积核与Inception](https://blog.csdn.net/a1154761720/article/details/53411365)\n",
    "    \n",
    "    解释了为什么 1×1 的卷积核可以做到降维（此处主要指的是减少通道数）和减少参数的效果。他是通过控制卷积核（通道数）来实现降维，也可以对不同特征进行尺寸的归一化；同时也可以用于不同channel上特征的融合。一个trick就是在降维的时候考虑结合传统的降维方式，如PCA的特征向量实现，这样效果也可以得到保证。\n",
    "    - [使用深度学习(CNN)算法进行图像识别工作时，有哪些data augmentation 的奇技淫巧？](https://www.zhihu.com/question/35339639)论文中，测试时图片裁剪策略的相关文章\n",
    "\n",
    "  **其他**\n",
    "    - [Wikipedia - 赫布理论（Hebbian theory)](https://zh.wikipedia.org/wiki/%E8%B5%AB%E5%B8%83%E7%90%86%E8%AE%BA) \n",
    "    \n",
    "    解释了学习的过程中脑中的神经元所发生的变化，它描述了突出的可塑性原理，即突触前神经元向突触后神经元的持续重复的刺激，可以导致突触传递效能的增加。\n",
    "    - [Wikipedia - 稀疏矩阵（sparse matrix）](https://en.wikipedia.org/wiki/Sparse_matrix)\n",
    "    - [Wikipedia_zh - 稀疏矩阵（sparse matrix）](https://zh.wikipedia.org/wiki/%E7%A8%80%E7%96%8F%E7%9F%A9%E9%98%B5)\n",
    "    - [A Gentle Introduction to Sparse Matrices for Machine Learning](https://machinelearningmastery.com/sparse-matrices-for-machine-learning/) 使用 python 对 sparse matrix 求解，附录有相关文章\n",
    "    - [mAP - 目标检测中的mean average precision是什么含义？](https://www.zhihu.com/question/53405779/answer/277013011)\n",
    "    - [Measuring Object Detection models - mAP - What is Mean Average Precision?](http://tarangshah.com/blog/2018-01-27/what-is-map-understanding-the-statistic-of-choice-for-comparing-object-detection-models/)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- [Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning](https://arxiv.org/abs/1602.07261)\n",
    "\n",
    "- [Xception: Deep Learning with Depthwise Separable Convolutions 1610.02357](https://arxiv.org/abs/1610.02357)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **VGGNet(Visual Geometry Group)**\n",
    "- [Very Deep Convolutional Networks for Large-Scale Visual Recognition](http://www.robots.ox.ac.uk/~vgg/research/very_deep/)\n",
    "  \n",
    "  **涉及论文**\n",
    "    - [Two-stream convolutional networks for action recognition in videos 1406.2199](https://arxiv.org/abs/1406.2199)\n",
    "    - [high performance convolutional neural networks for image classification - In IJCAI, pp. 1237–1242, 2011](http://people.idsia.ch/~juergen/ijcai2011.pdf)\n",
    "    - [Multi-digit Number Recognition from Street View Imagery using Deep Convolutional Neural Networks - Goodfellow et al 1312.6082](https://arxiv.org/abs/1312.6082)  提出增加网络深度，可以提到性能\n",
    "    - [Going Deeper with Convolutions - Szegedy et al 1409.4842](https://arxiv.org/abs/1409.4842) \n",
    "    \n",
    "    GooLeNet 独立于 VGG ，也是使用了更甚的网络和小的卷积 filter。结构比 VGG 更复杂，在第一层网络中，特征映射（feature maps）减少的更加激进。但在单网络（single-network）分类精度里，VGG 的执行性能更好。\n",
    "    - [**Overfeat: Integrated recognition, localization and detection using convolutional networks** - Sermanet et al 1312.6229](https://arxiv.org/abs/1312.6229)\n",
    "    - [One weird trick for parallelizing convolutional neural networks - Krizhevsky 1404.5997](https://arxiv.org/abs/1404.5997) 加速神经网络的训练\n",
    "  \n",
    "  **相关解读**\n",
    "    - [VGGNet 阅读理解 - Very Deep Convolutional Networks for Large-Scale Image Recognition](https://blog.csdn.net/zziahgf/article/details/79614822)\n",
    "    \n",
    "  **语义特征、图像特征 L2**\n",
    "    - [知乎 - 图像语义分割和普通的图像分割区别到底在哪呢？](https://www.zhihu.com/question/51567094)\n",
    "    \n",
    "    图像语义分割领域，语义主要指分割出来的物体的类别，从分割结果可以清楚的知道分割出来的是什么物体，比如猫、狗等等。现在还有一种叫instance segmentation, 可以对同一类别的不同物体进行不同的划分，可以清楚地知道分割出来的左边和右边的两个人不是同一个人。比如一排车连在一起，语义分割的结果是整个一排车在一个分割区域里，而instances segmentation还要将车与车分割开来。\n",
    "    - [CSDN - 图像处理中的L1-normalize 和L2-normalize](https://blog.csdn.net/a200800170331/article/details/21737741)\n",
    "  \n",
    "  **池化**\n",
    "    - [StackOverflow - What does global pooling do?](https://stackoverflow.com/questions/42070528/what-does-global-pooling-do)\n",
    "    - [CSDN - what is global average pooling ? 全局平均池化层](https://blog.csdn.net/qq_34650787/article/details/80204873) 有实例\n",
    "    - [CSDN - Global Average Pooling全局平均池化的一点理解](https://blog.csdn.net/qq_23304241/article/details/80292859) 有启发性\n",
    "  \n",
    "  **模型类型**\n",
    "  - [CSDN - 生成模型与判别模型](https://blog.csdn.net/zouxy09/article/details/8195017) 什么是判别性（discriminative）。\n",
    "    \n",
    "  **密集评估（dense evaluation）**\n",
    "    - [知乎 - VGG神经网络论文中multi-crop evaluation的结论什么意思？](https://www.zhihu.com/question/270988169)\n",
    "    - [CSDN - 深度学习（二十）基于Overfeat的图片分类、定位、检测](https://blog.csdn.net/hjimce/article/details/50187881)\n",
    "    - [CNBLOGS - VERY DEEP CONVOLUTIONAL NETWORKS FOR LARGE-SCALE IMAGE RECOGNITION 这篇论文](https://www.cnblogs.com/yinheyi/p/6233950.html) 参考了《测试网络的过程》\n",
    "    \n",
    "  **FC & FCN**\n",
    "    - [知乎 - 全连接层的作用是什么？](https://www.zhihu.com/question/41037974)\n",
    "    - [simshang - Fully Convolutional Networks](http://simtalk.cn/2016/11/01/Fully-Convolutional-Networks/)\n",
    "    \n",
    "  **IOU**\n",
    "    - [CSDN - 目标识别（object detection）中的 IoU（Intersection over Union）](https://blog.csdn.net/lanchunhui/article/details/71190055) 以下两篇介绍 IoU 的原理\n",
    "    - [CSDN - 检测评价函数 intersection-over-union （ IOU ）](https://blog.csdn.net/Eddy_zheng/article/details/52126641)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **ResNet**\n",
    "- [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385)\n",
    "  \n",
    "  **涉及论文**\n",
    "    - [【1】Learning long-term dependencies with gradient descent is difficult](http://www.iro.umontreal.ca/~lisa/pointeurs/ieeetrnn94.pdf)\n",
    "    - [【9】Understanding the difficulty of training deep feedforward neural networks](http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf)\n",
    "    - [【22】Backpropagation applied to handwritten zip code recognition](http://yann.lecun.com/exdb/publis/pdf/lecun-89e.pdf)\n",
    "    - [【21】imagenet-classification-with-deep-convolutional-neural-networks](http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks) AlexNet\n",
    "    - [【50】Visualizing and Understanding Convolutional Networks](https://arxiv.org/abs/1311.2901) ZFNet\n",
    "    - [【40】Overfeat: Integrated recognition, localization and detection using convolutional networks - 1312.6229](https://arxiv.org/abs/1312.6229) FCN\n",
    "    - [【41】Very Deep Convolutional Networks for Large-Scale Visual Recognition](http://www.robots.ox.ac.uk/~vgg/research/very_deep/) VGG\n",
    "    - [【16】Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift - 1502.03167](https://arxiv.org/abs/1502.03167) BN\n",
    "    - [【18】Aggregating local image descriptors into compact codes](https://hal.inria.fr/inria-00633013/document)  representation\n",
    "    - [【42】Highway networks - 1505.00387](https://arxiv.org/abs/1505.00387)\n",
    "    - [【43】Training Very Deep Networks](https://arxiv.org/abs/1507.06228)\n",
    "    - [On the number of linear regions of deep neural networks.](https://arxiv.org/abs/1402.1869)\n",
    "    \n",
    "  **扩展论文**\n",
    "    - [Identity Mappings in Deep Residual Networks - 1603.05027](https://arxiv.org/abs/1603.05027) ResNet 原作者对恒等映射的进一步解读\n",
    "    - [Residual Networks Behave Like Ensembles of Relatively Shallow Networks - 1605.06431](https://arxiv.org/abs/1605.06431) ResNet 的深度被狠狠的 diss 了一番，作者认为 ResNet 只不过是指数级别的模型集成。有意思。\n",
    "    \n",
    "  **相关解读**\n",
    "    - [CSDN - 对ResNet的理解](https://blog.csdn.net/buyi_shizi/article/details/53336192) ResNet其实是多人投票系统\n",
    "    - [知乎 - Deep Residual Network 深度残差网络](https://zhuanlan.zhihu.com/p/22447440) 网络相应分析\n",
    "    - [CSDN - ResNet解析](https://blog.csdn.net/lanran2/article/details/79057994) 映射，残差结构，结构分析\n",
    "    - [CSDN - 深度学习网络 | ResNet解析（2）](https://blog.csdn.net/u012426298/article/details/80848366) 升维降维操作\n",
    "    - [GITHUB.IO - DeepLearning笔记(8)——ResNet](https://syaning.github.io/2018/03/16/dl-resnet/)\n",
    "   \n",
    "  **连接**\n",
    "    - [REDDIT- Increasing dimension in residual block in Resnet](https://www.reddit.com/r/MachineLearning/comments/5lq48b/d_increasing_dimension_in_residual_block_in_resnet/)\n",
    "    - [知乎 - resnet（残差网络）的F（x）究竟长什么样子？](https://www.zhihu.com/question/53224378)\n",
    "    \n",
    "  **向量**\n",
    "    - [CSDN - Fisher Vector 通俗学习](https://blog.csdn.net/ikerpeng/article/details/41644197)\n",
    "    - [pluskid - 漫谈 Clustering (番外篇): Vector Quantization](http://blog.pluskid.org/?p=57)\n",
    "    - [CSDn - 语音信号处理之（三）矢量量化（Vector Quantization）](https://blog.csdn.net/zouxy09/article/details/9153255)\n",
    "    \n",
    "    \n",
    "- [Identity Mappings in Deep Residual Networks](https://arxiv.org/abs/1603.05027)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FCN**\n",
    "- [Fully Convolutional Networks for Semantic Segmentation - 1411.4038](https://arxiv.org/abs/1411.4038)\n",
    "- [Overfeat: Integrated recognition, localization and detection using convolutional networks - 1312.6229](https://arxiv.org/abs/1312.6229)\n",
    "  \n",
    "  **相关解读**\n",
    "    - [CNBLOGS - 对 OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks 一文的理解](http://www.cnblogs.com/yinheyi/p/6232152.html)\n",
    "  \n",
    "  **FC**\n",
    "    - [simshang - Fully Convolutional Networks](http://simtalk.cn/2016/11/01/Fully-Convolutional-Networks/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **R-CNN**\n",
    "- [Rich feature hierarchies for accurate object detection and semantic segmentation - 1311.2524v5](https://arxiv.org/pdf/1311.2524v5.pdf)\n",
    "\n",
    "  **涉及论文**\n",
    "    - [【7】Histograms of oriented gradients for human detection - 2005](https://lear.inrialpes.fr/people/triggs/pubs/Dalal-cvpr05.pdf) HOG\n",
    "    - [【29】 Distinctive image features from scale-invariant keypoints](https://www.cs.ubc.ca/~lowe/papers/ijcv04.pdf) SIFT\n",
    "    - [【25】4824-imagenet-classification-with-deep-convolutional-neural-networks](http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks) AlexNet \n",
    "    - [【38】Deep neural networks for object detection - 2013](https://papers.nips.cc/paper/5207-deep-neural-networks-for-object-detection.pdf) 把定位当做回归问题\n",
    "    - [【32】Neural networkbased face detection - 1998](https://courses.cs.washington.edu/courses/cse577/05sp/papers/rowley.pdf) 使用滑动窗口进行人脸检测\n",
    "    - [【40】Original approach for the localisation of objects in images - 1994](https://www.academia.edu/3073679/Original_approach_for_the_localisation_of_objects_in_images) 使用滑动窗口进行人脸检测\n",
    "    - [【35】Pedestrian Detection with Unsupervised Multi-Stage Feature Learning - 2013](https://arxiv.org/abs/1212.0142) 使用滑动窗口进行行人检测\n",
    "    - [【23】Diagnosing error in object detectors.](http://dhoiem.web.engr.illinois.edu/publications/eccv2012_detanalysis_derek.pdf)目标检测分析工具\n",
    "    - [【39】Selective search for object recognition - 2013](http://www.huppelen.nl/publications/selectiveSearchDraft.pdf) selective search 算法\n",
    "  \n",
    "  **扩展论文**\n",
    "  - [Rotated Region Based CNN for Ship Detection](http://www.escience.cn/system/file?fileId=90265) NMS 存在的问题\n",
    "    \n",
    "  **相关解读**\n",
    "    - [个站 - 论文笔记：Rich feature hierarchies for accurate object detection and semantic segmentation](http://jermmy.xyz/2017/05/08/2017-5-8-paper-notes-rcnn/)\n",
    "    - [个站 - 物体检测论文-RCNN](http://hellodfan.com/2017/09/26/%E7%89%A9%E4%BD%93%E6%A3%80%E6%B5%8B%E8%AE%BA%E6%96%87-RCNN/)\n",
    "    - [CSDN - RCNN学习笔记(2):Rich feature hierarchies for accurate object detection and semantic segmentation](https://blog.csdn.net/u011534057/article/details/51218250)\n",
    "    - [CSDN - R-CNN论文详解](https://blog.csdn.net/wopawn/article/details/52133338)\n",
    "  \n",
    "  **非极大值抑制（non-maximum supperssion NMS）**\n",
    "    - [CNBLOGS - 非极大值抑制（Non-Maximum Suppression，NMS）](https://www.cnblogs.com/makefile/p/nms.html)\n",
    "    - [CSDN - NMS——非极大值抑制](https://blog.csdn.net/shuzfan/article/details/52711706)\n",
    "    - [知乎 - 在Rcnn中为什么使用IoU非极大值抑制?](https://www.zhihu.com/question/46946022)\n",
    "    - [国外 - Non-Maximum Suppression for Object Detection in Python](https://www.pyimagesearch.com/2014/11/17/non-maximum-suppression-object-detection-python/)\n",
    "    - [个站 - 非极大值抑制](http://journeyfu.com/nms/)\n",
    "    \n",
    "  **各项同性/异性缩放**\n",
    "    - [QUORA - What is the meaning of isotropically-rescale in paper VGG?](https://www.quora.com/What-is-the-meaning-of-isotropically-rescale-in-paper-VGG)\n",
    "    - [stackoverflow - what is anisotropic scaling in computer vision?](https://stackoverflow.com/questions/43577231/what-is-anisotropic-scaling-in-computer-vision)\n",
    "    - [CSDN - 各向同性，各向异性缩放](https://blog.csdn.net/v1_vivian/article/details/80245397)\n",
    "    - [GITHUB - cqchu/Paper-about-Shanggang](https://github.com/cqchu/Paper-about-Shanggang/wiki/3.RCNN)\n",
    "    \n",
    "  **Hard Negative Mining（难分样本挖掘）**\n",
    "    - [REDDIT - What is hard negative mining? And how is it helpful in doing that while training classifiers?](https://www.reddit.com/r/computervision/comments/2ggc5l/what_is_hard_negative_mining_and_how_is_it/)\n",
    "    - [知乎 - rcnn中的Hard negative mining方法是如何实现的？](https://www.zhihu.com/question/46292829)\n",
    "    \n",
    "  **ablation study**\n",
    "    - [知乎 - 什么是 ablation study？](https://www.zhihu.com/question/60170398)\n",
    "    - [QUORA - In the context of deep learning, what is an ablation study?](https://www.quora.com/In-the-context-of-deep-learning-what-is-an-ablation-study)\n",
    "    - [个站 - What is ablation study in machine learning](http://qingkaikong.blogspot.com/2017/12/what-is-ablation-study-in-machine.html)\n",
    "    \n",
    "  **mAP（Mean Average Precision）**\n",
    "    - [**GITHUB - Most popular metrics used to evaluate object detection algorithms**](https://github.com/rafaelpadilla/Object-Detection-Metrics) mAP 的具体计算，建议阅读此文\n",
    "    - [MEDIUM - mAP (mean Average Precision) for Object Detection](https://medium.com/@jonathan_hui/map-mean-average-precision-for-object-detection-45c121a31173) \n",
    "    - [个站 - Measuring Object Detection models - mAP - What is Mean Average Precision?](http://tarangshah.com/blog/2018-01-27/what-is-map-understanding-the-statistic-of-choice-for-comparing-object-detection-models/)\n",
    "    - [CSDN - 目标检测模型中的性能评估——MAP(Mean Average Precision)](https://blog.csdn.net/Katherine_hsr/article/details/79266880) 和上文有很多相似的地方\n",
    "    - [CSDN - AP: average precision](https://blog.csdn.net/a1154761720/article/details/50864994)\n",
    "    - [stackoverflow - What is a threshold in a Precision-Recall curve?](https://stackoverflow.com/questions/46224752/what-is-a-threshold-in-a-precision-recall-curve)\n",
    "    - [知乎 - 目标检测中的mean average precision是什么含义？](https://www.zhihu.com/question/53405779/answer/277013011)\n",
    "    - [个站 - Introduction to the precision-recall plot](https://classeval.wordpress.com/introduction/introduction-to-the-precision-recall-plot/)\n",
    "  \n",
    "  **bounding-box Regression**\n",
    "    - [CSDN - 边框回归(Bounding Box Regression)详解](https://blog.csdn.net/zijin0802034/article/details/77685438)\n",
    "    - [caffe - bounding box regression](http://caffecn.cn/?/question/160)\n",
    "    - [Refining Bounding-Box Regression for Object Localization](http://web.cecs.pdx.edu/~mm/MastersTheses/NaomiDickersonThesis.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Fast R-CNN**\n",
    "- [Fast R-CNN - 1504.08083](https://arxiv.org/pdf/1504.08083.pdf)\n",
    "  \n",
    "  **涉及论文**\n",
    "    - [【3】Return of the Devil in the Details: Delving Deep into Convolutional Nets - 2014](https://arxiv.org/abs/1405.3531)\n",
    "    - [【5】Exploiting Linear Structure Within Convolutional Networks for Efficient Evaluation - 2014](https://arxiv.org/abs/1404.0736)\n",
    "    - [【9】Rich feature hierarchies for accurate object detection and semantic segmentation](https://arxiv.org/pdf/1311.2524v5.pdf) R-CNN\n",
    "    - [【11】Spatial pyramid pooling in deep convolutional networks for visual recognition](https://arxiv.org/abs/1406.4729) SPPNet\n",
    "    - [【14】imagenet-classification-with-deep-convolutional-neural-networks](http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks) AlexNet\n",
    "    - [【19】Overfeat: Integrated recognition, localization and detection using convolutional networks](https://arxiv.org/abs/1312.6229) OverFeat\n",
    "    - [【20】Very Deep Convolutional Networks for Large-Scale Visual Recognition](http://www.robots.ox.ac.uk/~vgg/research/very_deep/) VGG\n",
    "    - [【23】Restructuring of deep neural network acoustic models with singular value decomposition - 2013](https://www.microsoft.com/en-us/research/wp-content/uploads/2013/01/svd_v2.pdf) SVD 在 fc 中的应用\n",
    "    - [【24】Do We Need More Training Data?- 2015](https://arxiv.org/abs/1503.01508) 使用的是 arXiv 的标题\n",
    "    - [【25】segDeepM: Exploiting segmentation and context in deep neural networks for object detection](https://arxiv.org/abs/1502.04275)\n",
    "\n",
    "  **相关解读**\n",
    "    - [Ross Girshick - fast r-cnn slides](http://www.robots.ox.ac.uk/~tvg/publications/talks/fast-rcnn-slides.pdf)\n",
    "    - [CSDN - 【目标检测】Fast RCNN算法详解](https://blog.csdn.net/shenxiaolu1984/article/details/51036677)\n",
    "    \n",
    "  **RoI**\n",
    "    - [reddit - I am struggling to understand the difference between max pooling and RoI max pooling.](https://www.reddit.com/r/MachineLearning/comments/4wsv4e/i_am_struggling_to_understand_the_difference/)\n",
    "    - [reddit - Why does Mask RCNN use Max ROI Pooling? Why not average?](https://www.reddit.com/r/computervision/comments/8wowmu/why_does_mask_rcnn_use_max_roi_pooling_why_not/)\n",
    "    - [个站 - Region of interest pooling explained](https://deepsense.ai/region-of-interest-pooling-explained/)\n",
    "    - [CSDN - ROI Pooling层详解](https://blog.csdn.net/AUTO1993/article/details/78514071) 对上文的翻译，可以看看评论\n",
    "    - [leanote - 详解 ROI Align 的基本原理和实现细节](http://blog.leanote.com/post/afanti.deng@gmail.com/b5f4f526490b)\n",
    "    - [github - deepsense-ai/roi-pooling](https://github.com/deepsense-ai/roi-pooling) 动图与实现\n",
    "    \n",
    "  **不变性（invariance）**\n",
    "    - [quora - How is a convolutional neural network able to learn invariant features?](https://www.quora.com/How-is-a-convolutional-neural-network-able-to-learn-invariant-features)\n",
    "    - [github.io - Yes, Convolutional Neural Nets do care about Scale](https://miguel-data-sc.github.io/2017-11-23-second/)\n",
    "    - [arXiv - Learning scale-variant and scale-invariant features for deep image classification - 2016](https://arxiv.org/abs/1602.01255)\n",
    "    \n",
    "  **end-to-end**\n",
    "    - [coursera - What is end-to-end deep learning?](https://www.coursera.org/lecture/machine-learning-projects/what-is-end-to-end-deep-learning-k0Klk)\n",
    "    - [知乎 - 什么是 end-to-end 神经网络？](https://www.zhihu.com/question/51435499)\n",
    "    - [quora - What does end to end mean in deep learning methods?](https://www.quora.com/What-does-end-to-end-mean-in-deep-learning-methods/answer/Alan-Lockett-2)\n",
    "    - [简书 - end-to-end 究竟是什么意思](https://www.jianshu.com/p/3702dcda603c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Faster R-CNN**\n",
    "- [Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks - 506.01497](https://arxiv.org/pdf/1506.01497v3.pdf)\n",
    "\n",
    "  **涉及论文**\n",
    "    - [【1】Spatial pyramid pooling in deep convolutional networks for visual recognition](https://arxiv.org/abs/1406.4729) SPPNet\n",
    "    - [【2】Fast R-CNN - 2015](https://arxiv.org/pdf/1504.08083.pdf)Fast R-CNN\n",
    "    - [【3】Very Deep Convolutional Networks for Large-Scale Visual Recognition - 2015](http://www.robots.ox.ac.uk/~vgg/research/very_deep/) VGG\n",
    "    - [【4】Selective search for object recognition - 2013](http://www.huppelen.nl/publications/selectiveSearchDraft.pdf) selective search 算法\n",
    "    - [【5】Rich feature hierarchies for accurate object detection and semantic segmentation - 1311.2524v5](https://arxiv.org/pdf/1311.2524v5.pdf) R-CNN\n",
    "    - [【6】Edge Boxes: Locating Object Proposals from Edges - 2014](https://pdollar.github.io/files/papers/ZitnickDollarECCV14edgeBoxes.pdf) EdgeBoxes\n",
    "    - [【7】Fully Convolutional Networks for Semantic Segmentation - 1411.4038](https://arxiv.org/abs/1411.4038) FCN\n",
    "    - [【13】Deep sliding shapes for amodal 3d object detection in rgb-d images - 2015](http://dss.cs.princeton.edu/paper.pdf) 3D object detection\n",
    "    - [【14】DeePM: A deep part-based model for object detection and semantic part localization - 1511.07131](https://arxiv.org/abs/1511.07131) part-based detection\n",
    "    - [【15】Instance-aware Semantic Segmentation via Multi-task Network Cascades - 1512.04412](https://arxiv.org/abs/1512.04412) instance segmentation\n",
    "    - [【16】DenseCap: Fully Convolutional Localization Networks for Dense Captioning - 2015](https://cs.stanford.edu/people/karpathy/densecap/) image captioning\n",
    "    - [【18】Deep Residual Learning for Image Recognition - 2015](https://arxiv.org/abs/1512.03385) ResNet\n",
    "    - [【20】What makes for effective detection proposals? - 2015](https://arxiv.org/abs/1502.05082)\n",
    "    - [【31】Attention-based models for speech recognition - 1506.07503](https://arxiv.org/abs/1506.07503)Attention-based model\n",
    "    - [【32】Visualizing and Understanding Convolutional Networks - 1311.2901](https://arxiv.org/abs/1311.2901) ZFNet\n",
    "  \n",
    "  **论文解读**\n",
    "    - [cnblogs - Faster R-CNN](https://www.cnblogs.com/nowgood/p/FasterRCNN.html)\n",
    "    - [知乎 - 一文读懂Faster RCNN](https://zhuanlan.zhihu.com/p/31426458)\n",
    "    - [个站 - Object Detection and Classification using R-CNNs](http://www.telesens.co/2018/03/11/object-detection-and-classification-using-r-cnns/)\n",
    "    - [CSDN - faster-rcnn 原理解析 ](https://blog.csdn.net/lanyuelvyun/article/details/77720260)\n",
    "    - [cnblogs - Faster R-CNN论文详解](https://www.cnblogs.com/xuanyuyt/p/6209910.html)\n",
    "    - [个站 - Faster R-CNN: Down the rabbit hole of modern object detection](https://tryolabs.com/blog/2018/01/18/faster-r-cnn-down-the-rabbit-hole-of-modern-object-detection/)\n",
    "    \n",
    "  **neural network with attention**\n",
    "    - [知乎- Attention based model 是什么，它解决了什么问题？](https://www.zhihu.com/question/36591394)\n",
    "    - [github.io - Attention in Neural Networks and How to Use It](http://akosiorek.github.io/ml/2017/10/14/visual-attention.html)\n",
    "    - [reddit - Attention in Neural Networks and How to Use It](https://www.reddit.com/r/MachineLearning/comments/76j5lo/d_attention_in_neural_networks_and_how_to_use_it/)\n",
    "    - [quora - What is Attention Mechanism in Neural Networks?](https://www.quora.com/What-is-Attention-Mechanism-in-Neural-Networks)\n",
    "    - [medium - A Brief Overview of Attention Mechanism](https://medium.com/syncedreview/a-brief-overview-of-attention-mechanism-13c578ba9129)\n",
    "    \n",
    "  **维度问题**\n",
    "    - [github - Why does it need a reshape layer in RPN's cls layer](https://github.com/rbgirshick/py-faster-rcnn/issues/292)\n",
    "    - [caffecn - py-faster rcnn中rpn的3x3的滑框用卷积层来定义的是为什么？](http://caffecn.cn/?/question/449)\n",
    "    \n",
    "  **anchor 生成**\n",
    "    - [quora - How does the region proposal network (RPN) in Faster R-CNN work?](https://www.quora.com/How-does-the-region-proposal-network-RPN-in-Faster-R-CNN-work)\n",
    "    - [medium - Faster R-CNN Explained](https://medium.com/@smallfishbigsea/faster-r-cnn-explained-864d4fb7e3f8)\n",
    "    - [知乎 - faster rcnn中rpn的anchor，sliding windows，proposals？](https://www.zhihu.com/question/42205480)\n",
    "    - [CSDN - Faster-RCNN算法精读](https://blog.csdn.net/hunterlew/article/details/71075925)\n",
    "  \n",
    "  **stride 问题**\n",
    "    - [google - Understanding Faster-RCNN training input size](https://groups.google.com/forum/#!msg/caffe-users/E5l9C_QfcmI/iDegegMQBgAJ)\n",
    "    - [github - Changing stride length decreased object detection accuracy](https://github.com/rbgirshick/py-faster-rcnn/issues/294)\n",
    "    - [掘金 - 卷积神经网络模型解读汇总](https://juejin.im/post/5ae283c4f265da0b886d2323)\n",
    "  \n",
    "  **Faster RCNN 结构**\n",
    "    - [个站 - “Fast R-CNN and Faster R-CNN”](https://jhui.github.io/2017/03/15/Fast-R-CNN-and-Faster-R-CNN/)\n",
    "    \n",
    "  **RPN**\n",
    "    - [CSDN - 深度学习: RPN (区域候选网络)](https://blog.csdn.net/JNingWei/article/details/78847696)\n",
    "    - [个站 - Notes on Faster RCNN](http://shuokay.com/2018/01/27/faster-rcnn/)\n",
    "    - [CSDN - 详细的Faster R-CNN源码解析之RPN源码解析](https://blog.csdn.net/jiongnima/article/details/79781792)\n",
    "    \n",
    "  **stage**\n",
    "    - [CSDN - 深度学习: one-stage/two-stage/multi-stage 目标检测算法](https://blog.csdn.net/JNingWei/article/details/80039079)\n",
    "    - [知乎 - 检测任务专题2: two-stage检测](https://zhuanlan.zhihu.com/p/30621997)\n",
    "    \n",
    "  **caffe layer**\n",
    "    - [简书 - 在Caffe中加Python Layer的方法](https://www.jianshu.com/p/e05d1b210fcb)\n",
    "    - [简书 - 深度学习caffe框架(2): layer定义](https://www.jianshu.com/p/e397c2ed034b)\n",
    "    \n",
    "  **faster r-cnn 训练**\n",
    "    - [个站 - Training R-CNNs of various velocities Slow, fast, and faster](http://ow680yzep.bkt.clouddn.com/iccv15_tutorial_training_rbg.pdf) rbg 大神的Faster R-CNN 讲座\n",
    "    - [知乎 - Faster-RCNN四步交替法源码阅读笔记](https://zhuanlan.zhihu.com/p/34327246)\n",
    "    - [知乎 - 从编程实现角度学习Faster R-CNN（附极简实现）](https://zhuanlan.zhihu.com/p/32404424) 其中的模型架构图可以清楚的看到反向传播是怎么发生的。\n",
    "    - [CSDN - 详细的Faster R-CNN源码解析之proposal_layer和proposal_target_layer源码解析](https://blog.csdn.net/jiongnima/article/details/80478597)\n",
    "    - [CSDn - faster rcnn源码解读（五）之layer（网络里的input-data）](https://blog.csdn.net/u010668907/article/details/51945844) RoIDataLayer\n",
    "    - [CSDN - faster-rcnn 之 基于roidb get_minibatch（数据准备操作）](https://blog.csdn.net/sloanqin/article/details/51611747)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Mask R-CNN**\n",
    "- [Mask R-CNN - 1703.06870](https://arxiv.org/abs/1703.06870)\n",
    "  \n",
    "  **涉及论文**\n",
    "    - [【9】Convolutional feature masking for joint object and stuff segmentation - 1412.1283](https://arxiv.org/abs/1412.1283)\n",
    "    - [【10】Instance-aware Semantic Segmentation via Multi-task Network Cascades - 1512.04412](https://arxiv.org/abs/1512.04412) MNC、instance segmentation、RoIWarp\n",
    "    - [【12】Fast R-CNN - 1504.08083](https://arxiv.org/pdf/1504.08083.pdf) Fast R-CNN\n",
    "    - [【13】Rich feature hierarchies for accurate object detection and semantic segmentation - 1311.2524v5](https://arxiv.org/pdf/1311.2524v5.pdf) R-CNN\n",
    "    - [【21】 Speed/accuracy trade-offs for modern convolutional object\n",
    "detectors - 1611.10012](https://arxiv.org/abs/1611.10012) G-RMI\n",
    "    - [【22】Spatial Transformer Networks - 1506.02025](https://arxiv.org/abs/1506.02025)\n",
    "    - [【26】Fully Convolutional Instance-aware Semantic Segmentation - 1611.07709](https://arxiv.org/abs/1611.07709) FCIS\n",
    "    - [【27】Feature Pyramid Networks for Object Detection - 1612.03144](https://arxiv.org/abs/1612.03144) FPN\n",
    "    - [【36】Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks - 506.01497](https://arxiv.org/pdf/1506.01497v3.pdf) Faster R-CNN\n",
    "    - [【30】Fully Convolutional Networks for Semantic Segmentation - 1411.4038](https://arxiv.org/abs/1411.4038) FCN\n",
    "    - [【18】Spatial pyramid pooling in deep convolutional networks for visual recognition - 1406.4729](https://arxiv.org/abs/1406.4729) SPPNet\n",
    "    - [【33】Learning to Segment Object Candidates - 1506.06204](https://arxiv.org/abs/1506.06204)\n",
    "    - [【38】Training Region-based Object Detectors with Online Hard Example Mining - 1604.03540](https://arxiv.org/abs/1604.03540) OHEM\n",
    "    \n",
    "  **相关解读**\n",
    "    - [CSDN - Mask RCNN笔记](https://blog.csdn.net/xiamentingtao/article/details/78598511)\n",
    "    - [CSDN - Mask-RCNN技术解析](https://blog.csdn.net/linolzhang/article/details/71774168)\n",
    "    - [CSDN - 【目标检测】Mask RCNN算法详解](https://blog.csdn.net/disiwei1012/article/details/79508839)\n",
    "    - [slides - Mask R-CNN:A Perspective on\tEquivariance](http://kaiminghe.com/iccv17tutorial/maskrcnn_iccv2017_tutorial_kaiminghe.pdf)\n",
    "    \n",
    "  **相关术语**\n",
    "    - [知乎 - 图像识别中，目标分割、目标识别、目标检测和目标跟踪这几个方面区别是什么？](https://www.zhihu.com/question/36500536)\n",
    "    - [CSDN - 图像分类，物体检测，语义分割，实例分割等概念](https://blog.csdn.net/u010821666/article/details/78697723)\n",
    "    \n",
    "  **RoIAlign**\n",
    "    - [github - RoI pooling in TensorFlow](https://github.com/deepsense-ai/roi-pooling)\n",
    "    - [个站 - 详解 ROI Align 的基本原理和实现细节](http://blog.leanote.com/post/afanti.deng@gmail.com/b5f4f526490b)\n",
    "    - [cnblogs - RoIPooling、RoIAlign笔记](https://www.cnblogs.com/wangyong/p/8523814.html)\n",
    "    \n",
    "  **应用**\n",
    "    - [github - Mask R-CNN for object detection and instance segmentation on Keras and TensorFlow](https://github.com/matterport/Mask_RCNN) 不错的实际应用与理论教程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GAN**\n",
    "- [Generative Adversarial Nets 1406.2661](https://arxiv.org/abs/1406.2661)\n",
    "- [NIPS 2016 Tutorial: Generative Adversarial Networks 1701.00160](https://arxiv.org/abs/1701.00160)\n",
    "\n",
    "\n",
    "- [Image Inpainting for Irregular Holes Using Partial Convolutions 1804.07723](https://arxiv.org/abs/1804.07723)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 可视化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [RCNN-Rich feature hierarchies for accurate object detection and semantic segmentation](https://arxiv.org/abs/1311.2524)\n",
    "- [ZFNet-Visualizing and Understanding Convolutional Networks](https://arxiv.org/abs/1311.2901)\n",
    "- [Understanding Deep Image Representations by Inverting Them](https://arxiv.org/abs/1412.0035)\n",
    "- [Do Convnets Learn Correspondence?](http://papers.nips.cc/paper/5420-do-convnets-learn-correspondence.pdf)\n",
    "- [ImageNet Large Scale Visual Recognition Challenge](https://arxiv.org/abs/1409.0575)\n",
    "- [Explaining and Harnessing Adversarial Examples](https://arxiv.org/abs/1412.6572)\n",
    "- [What I learned from competing against a ConvNet on ImageNet](http://karpathy.github.io/2014/09/02/what-i-learned-from-competing-against-a-convnet-on-imagenet/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实用技巧"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [A practical theory for designing very deep convolutional neural networks](https://kaggle2.blob.core.windows.net/forum-message-attachments/69182/2287/A%20practical%20theory%20for%20designing%20very%20deep%20convolutional%20neural%20networks.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**池化层（Pooling）探讨**\n",
    "- [Striving for Simplicity: The All Convolutional Net](https://arxiv.org/abs/1412.6806)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os,fnmatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['93_0.jpg', '121_5.jpg', '164_5.jpg', '184_0.jpg', '36_5.jpg', '73_5.jpg', '179_0.jpg', '48_3.jpg', '199_5.jpg', '91_2.jpg', '105_4.jpg', '140_4.jpg', '12_4.jpg', '57_4.jpg', '186_2.jpg', '118_1.jpg', '29_2.jpg', '103_2.jpg', '8_0.jpg', '146_2.jpg', '160_1.jpg', '125_1.jpg', '97_4.jpg', '77_1.jpg', '32_1.jpg', '180_4.jpg', '14_2.jpg', '51_2.jpg', '138_4.jpg', '144_0.jpg', '101_0.jpg', '127_3.jpg', '162_3.jpg', '30_3.jpg', '75_3.jpg', '53_0.jpg', '16_0.jpg', '159_5.jpg', '200_0.jpg', '88_3.jpg', '88_2.jpg', '159_4.jpg', '200_1.jpg', '53_1.jpg', '16_1.jpg', '30_2.jpg', '75_2.jpg', '127_2.jpg', '162_2.jpg', '144_1.jpg', '101_1.jpg', '138_5.jpg', '14_3.jpg', '51_3.jpg', '77_0.jpg', '180_5.jpg', '32_0.jpg', '160_0.jpg', '97_5.jpg', '125_0.jpg', '8_1.jpg', '103_3.jpg', '146_3.jpg', '29_3.jpg', '118_0.jpg', '186_3.jpg', '12_5.jpg', '57_5.jpg', '105_5.jpg', '140_5.jpg', '91_3.jpg', '199_4.jpg', '48_2.jpg', '179_1.jpg', '36_4.jpg', '184_1.jpg', '73_4.jpg', '121_4.jpg', '93_1.jpg', '164_4.jpg', '107_5.jpg', '142_5.jpg', '93_3.jpg', '184_3.jpg', '10_5.jpg', '55_5.jpg', '179_3.jpg', '48_0.jpg', '123_4.jpg', '91_1.jpg', '166_4.jpg', '34_4.jpg', '186_1.jpg', '71_4.jpg', '118_2.jpg', '29_1.jpg', '125_2.jpg', '160_2.jpg', '146_1.jpg', '103_1.jpg', '8_3.jpg', '51_1.jpg', '14_1.jpg', '32_2.jpg', '77_2.jpg', '162_0.jpg', '95_5.jpg', '127_0.jpg', '101_3.jpg', '144_3.jpg', '16_3.jpg', '53_3.jpg', '75_0.jpg', '182_5.jpg', '30_0.jpg', '88_0.jpg', '200_3.jpg', '68_5.jpg', '68_4.jpg', '200_2.jpg', '88_1.jpg', '75_1.jpg', '30_1.jpg', '182_4.jpg', '16_2.jpg', '53_2.jpg', '101_2.jpg', '144_2.jpg', '162_1.jpg', '127_1.jpg', '95_4.jpg', '32_3.jpg', '77_3.jpg', '51_0.jpg', '14_0.jpg', '146_0.jpg', '8_2.jpg', '103_0.jpg', '125_3.jpg', '160_3.jpg', '29_0.jpg', '118_3.jpg', '186_0.jpg', '34_5.jpg', '71_5.jpg', '91_0.jpg', '123_5.jpg', '166_5.jpg', '48_1.jpg', '179_2.jpg', '10_4.jpg', '55_4.jpg', '184_2.jpg', '93_2.jpg', '107_4.jpg', '142_4.jpg', '36_3.jpg', '73_3.jpg', '55_0.jpg', '10_0.jpg', '142_0.jpg', '107_0.jpg', '121_3.jpg', '164_3.jpg', '199_3.jpg', '48_5.jpg', '71_1.jpg', '34_1.jpg', '186_4.jpg', '12_2.jpg', '57_2.jpg', '105_2.jpg', '140_2.jpg', '166_1.jpg', '123_1.jpg', '91_4.jpg', '29_4.jpg', '14_4.jpg', '51_4.jpg', '180_2.jpg', '97_2.jpg', '103_4.jpg', '146_4.jpg', '138_2.jpg', '182_0.jpg', '30_5.jpg', '75_5.jpg', '95_0.jpg', '127_5.jpg', '162_5.jpg', '68_0.jpg', '88_5.jpg', '159_3.jpg', '159_2.jpg', '88_4.jpg', '68_1.jpg', '127_4.jpg', '95_1.jpg', '162_4.jpg', '30_4.jpg', '182_1.jpg', '75_4.jpg', '138_3.jpg', '103_5.jpg', '146_5.jpg', '97_3.jpg', '180_3.jpg', '14_5.jpg', '51_5.jpg', '29_5.jpg', '166_0.jpg', '91_5.jpg', '123_0.jpg', '105_3.jpg', '140_3.jpg', '12_3.jpg', '57_3.jpg', '71_0.jpg', '186_5.jpg', '34_0.jpg', '48_4.jpg', '199_2.jpg', '121_2.jpg', '164_2.jpg', '142_1.jpg', '107_1.jpg', '55_1.jpg', '10_1.jpg', '36_2.jpg', '73_2.jpg', '10_3.jpg', '55_3.jpg', '73_0.jpg', '184_5.jpg', '36_0.jpg', '164_0.jpg', '93_5.jpg', '121_0.jpg', '107_3.jpg', '142_3.jpg', '199_0.jpg', '179_5.jpg', '57_1.jpg', '12_1.jpg', '34_2.jpg', '71_2.jpg', '123_2.jpg', '166_2.jpg', '140_1.jpg', '105_1.jpg', '118_4.jpg', '32_4.jpg', '180_1.jpg', '77_4.jpg', '8_5.jpg', '125_4.jpg', '97_1.jpg', '160_4.jpg', '138_1.jpg', '182_3.jpg', '16_5.jpg', '53_5.jpg', '101_5.jpg', '144_5.jpg', '95_3.jpg', '68_3.jpg', '200_5.jpg', '159_0.jpg', '200_4.jpg', '159_1.jpg', '68_2.jpg', '95_2.jpg', '101_4.jpg', '144_4.jpg', '16_4.jpg', '53_4.jpg', '182_2.jpg', '138_0.jpg', '97_0.jpg', '125_5.jpg', '160_5.jpg', '8_4.jpg', '180_0.jpg', '32_5.jpg', '77_5.jpg', '118_5.jpg', '140_0.jpg', '105_0.jpg', '123_3.jpg', '166_3.jpg', '34_3.jpg', '71_3.jpg', '57_0.jpg', '12_0.jpg', '179_4.jpg', '199_1.jpg', '107_2.jpg', '142_2.jpg', '164_1.jpg', '121_1.jpg', '93_4.jpg', '73_1.jpg', '36_1.jpg', '184_4.jpg', '10_2.jpg', '55_2.jpg', '126_0.jpg', '94_5.jpg', '163_0.jpg', '145_3.jpg', '100_3.jpg', '52_3.jpg', '17_3.jpg', '31_0.jpg', '183_5.jpg', '74_0.jpg', '89_0.jpg', '201_3.jpg', '69_5.jpg', '161_2.jpg', '124_2.jpg', '102_1.jpg', '9_3.jpg', '147_1.jpg', '15_1.jpg', '50_1.jpg', '76_2.jpg', '33_2.jpg', '167_4.jpg', '90_1.jpg', '122_4.jpg', '70_4.jpg', '187_1.jpg', '35_4.jpg', '119_2.jpg', '28_1.jpg', '143_5.jpg', '106_5.jpg', '92_3.jpg', '185_3.jpg', '54_5.jpg', '11_5.jpg', '178_3.jpg', '49_0.jpg', '49_1.jpg', '178_2.jpg', '54_4.jpg', '11_4.jpg', '185_2.jpg', '92_2.jpg', '143_4.jpg', '106_4.jpg', '28_0.jpg', '119_3.jpg', '70_5.jpg', '35_5.jpg', '187_0.jpg', '167_5.jpg', '122_5.jpg', '90_0.jpg', '76_3.jpg', '33_3.jpg', '15_0.jpg', '50_0.jpg', '9_2.jpg', '102_0.jpg', '147_0.jpg', '161_3.jpg', '124_3.jpg', '69_4.jpg', '201_2.jpg', '89_1.jpg', '183_4.jpg', '31_1.jpg', '74_1.jpg', '52_2.jpg', '17_2.jpg', '145_2.jpg', '100_2.jpg', '94_4.jpg', '126_1.jpg', '163_1.jpg', '100_0.jpg', '145_0.jpg', '163_3.jpg', '126_3.jpg', '74_3.jpg', '31_3.jpg', '17_0.jpg', '52_0.jpg', '201_0.jpg', '158_5.jpg', '89_3.jpg', '147_2.jpg', '102_2.jpg', '9_0.jpg', '96_4.jpg', '124_1.jpg', '161_1.jpg', '181_4.jpg', '33_1.jpg', '76_1.jpg', '50_2.jpg', '15_2.jpg', '139_4.jpg', '90_2.jpg', '141_4.jpg', '104_4.jpg', '56_4.jpg', '13_4.jpg', '187_2.jpg', '119_1.jpg', '28_2.jpg', '165_5.jpg', '120_5.jpg', '92_0.jpg', '72_5.jpg', '37_5.jpg', '185_0.jpg', '178_0.jpg', '49_3.jpg', '198_5.jpg', '198_4.jpg', '49_2.jpg', '178_1.jpg', '72_4.jpg', '185_1.jpg', '37_4.jpg', '165_4.jpg', '92_1.jpg', '120_4.jpg', '28_3.jpg', '119_0.jpg', '187_3.jpg', '56_5.jpg', '13_5.jpg', '141_5.jpg', '104_5.jpg', '90_3.jpg', '139_5.jpg', '50_3.jpg', '15_3.jpg', '33_0.jpg', '181_5.jpg', '76_0.jpg', '124_0.jpg', '96_5.jpg', '161_0.jpg', '147_3.jpg', '9_1.jpg', '102_3.jpg', '89_2.jpg', '201_1.jpg', '158_4.jpg', '17_1.jpg', '52_1.jpg', '74_2.jpg', '31_2.jpg', '163_2.jpg', '126_2.jpg', '100_1.jpg', '145_1.jpg', '183_3.jpg', '52_5.jpg', '17_5.jpg', '145_5.jpg', '100_5.jpg', '94_3.jpg', '69_3.jpg', '158_0.jpg', '201_5.jpg', '76_4.jpg', '181_1.jpg', '33_4.jpg', '9_5.jpg', '161_4.jpg', '96_1.jpg', '124_4.jpg', '139_1.jpg', '13_1.jpg', '56_1.jpg', '70_2.jpg', '35_2.jpg', '167_2.jpg', '122_2.jpg', '104_1.jpg', '141_1.jpg', '119_4.jpg', '54_3.jpg', '11_3.jpg', '37_0.jpg', '185_5.jpg', '72_0.jpg', '120_0.jpg', '92_5.jpg', '165_0.jpg', '143_3.jpg', '106_3.jpg', '198_0.jpg', '178_5.jpg', '178_4.jpg', '198_1.jpg', '143_2.jpg', '106_2.jpg', '92_4.jpg', '120_1.jpg', '165_1.jpg', '185_4.jpg', '37_1.jpg', '72_1.jpg', '54_2.jpg', '11_2.jpg', '119_5.jpg', '104_0.jpg', '141_0.jpg', '167_3.jpg', '122_3.jpg', '70_3.jpg', '35_3.jpg', '13_0.jpg', '56_0.jpg', '139_0.jpg', '161_5.jpg', '124_5.jpg', '96_0.jpg', '9_4.jpg', '76_5.jpg', '33_5.jpg', '181_0.jpg', '158_1.jpg', '201_4.jpg', '69_2.jpg', '94_2.jpg', '145_4.jpg', '100_4.jpg', '52_4.jpg', '17_4.jpg', '183_2.jpg', '74_5.jpg', '31_5.jpg', '183_0.jpg', '163_5.jpg', '126_5.jpg', '94_0.jpg', '69_0.jpg', '89_5.jpg', '158_3.jpg', '50_4.jpg', '15_4.jpg', '181_2.jpg', '96_2.jpg', '147_4.jpg', '102_4.jpg', '139_2.jpg', '187_4.jpg', '35_1.jpg', '70_1.jpg', '56_2.jpg', '13_2.jpg', '141_2.jpg', '104_2.jpg', '90_4.jpg', '122_1.jpg', '167_1.jpg', '28_4.jpg', '72_3.jpg', '37_3.jpg', '11_0.jpg', '54_0.jpg', '106_0.jpg', '143_0.jpg', '165_3.jpg', '120_3.jpg', '198_3.jpg', '49_5.jpg', '49_4.jpg', '198_2.jpg', '165_2.jpg', '120_2.jpg', '106_1.jpg', '143_1.jpg', '11_1.jpg', '54_1.jpg', '72_2.jpg', '37_2.jpg', '28_5.jpg', '122_0.jpg', '90_5.jpg', '167_0.jpg', '141_3.jpg', '104_3.jpg', '56_3.jpg', '13_3.jpg', '35_0.jpg', '187_5.jpg', '70_0.jpg', '139_3.jpg', '147_5.jpg', '102_5.jpg', '96_3.jpg', '181_3.jpg', '50_5.jpg', '15_5.jpg', '158_2.jpg', '89_4.jpg', '69_1.jpg', '163_4.jpg', '94_1.jpg', '126_4.jpg', '74_4.jpg', '183_1.jpg', '31_4.jpg', '41_0.jpg', '22_3.jpg', '67_3.jpg', '135_3.jpg', '170_3.jpg', '156_0.jpg', '113_0.jpg', '19_5.jpg', '43_2.jpg', '65_1.jpg', '20_1.jpg', '192_4.jpg', '172_1.jpg', '137_1.jpg', '85_4.jpg', '111_2.jpg', '154_2.jpg', '78_4.jpg', '98_1.jpg', '7_5.jpg', '194_2.jpg', '45_4.jpg', '117_4.jpg', '152_4.jpg', '83_2.jpg', '58_1.jpg', '1_3.jpg', '169_2.jpg', '196_0.jpg', '24_5.jpg', '61_5.jpg', '81_0.jpg', '133_5.jpg', '176_5.jpg', '39_0.jpg', '108_3.jpg', '3_1.jpg', '3_0.jpg', '108_2.jpg', '39_1.jpg', '133_4.jpg', '81_1.jpg', '176_4.jpg', '24_4.jpg', '196_1.jpg', '61_4.jpg', '169_3.jpg', '1_2.jpg', '58_0.jpg', '83_3.jpg', '117_5.jpg', '152_5.jpg', '45_5.jpg', '194_3.jpg', '7_4.jpg', '98_0.jpg', '78_5.jpg', '111_3.jpg', '154_3.jpg', '172_0.jpg', '85_5.jpg', '137_0.jpg', '65_0.jpg', '192_5.jpg', '20_0.jpg', '43_3.jpg', '19_4.jpg', '156_1.jpg', '113_1.jpg', '135_2.jpg', '170_2.jpg', '22_2.jpg', '67_2.jpg', '41_1.jpg', '67_0.jpg', '190_5.jpg', '22_0.jpg', '41_3.jpg', '113_3.jpg', '156_3.jpg', '170_0.jpg', '87_5.jpg', '135_0.jpg', '5_4.jpg', '128_5.jpg', '20_2.jpg', '65_2.jpg', '43_1.jpg', '154_1.jpg', '111_1.jpg', '137_2.jpg', '172_2.jpg', '149_4.jpg', '98_2.jpg', '26_4.jpg', '194_1.jpg', '63_4.jpg', '131_4.jpg', '83_1.jpg', '174_4.jpg', '58_2.jpg', '189_4.jpg', '169_1.jpg', '1_0.jpg', '47_5.jpg', '196_3.jpg', '81_3.jpg', '115_5.jpg', '150_5.jpg', '39_3.jpg', '108_0.jpg', '3_2.jpg', '3_3.jpg', '108_1.jpg', '39_2.jpg', '115_4.jpg', '150_4.jpg', '81_2.jpg', '196_2.jpg', '47_4.jpg', '1_1.jpg', '169_0.jpg', '189_5.jpg', '58_3.jpg', '83_0.jpg', '131_5.jpg', '174_5.jpg', '194_0.jpg', '26_5.jpg', '63_5.jpg', '98_3.jpg', '149_5.jpg', '137_3.jpg', '172_3.jpg', '154_0.jpg', '111_0.jpg', '43_0.jpg', '20_3.jpg', '65_3.jpg', '128_4.jpg', '5_5.jpg', '170_1.jpg', '135_1.jpg', '87_4.jpg', '113_2.jpg', '156_2.jpg', '41_2.jpg', '67_1.jpg', '22_1.jpg', '190_4.jpg', '87_0.jpg', '135_5.jpg', '170_5.jpg', '190_0.jpg', '22_5.jpg', '67_5.jpg', '5_1.jpg', '128_0.jpg', '19_3.jpg', '111_4.jpg', '154_4.jpg', '85_2.jpg', '192_2.jpg', '43_4.jpg', '7_3.jpg', '149_1.jpg', '78_2.jpg', '174_1.jpg', '131_1.jpg', '83_4.jpg', '117_2.jpg', '152_2.jpg', '45_2.jpg', '63_1.jpg', '26_1.jpg', '194_4.jpg', '169_4.jpg', '1_5.jpg', '189_1.jpg', '133_3.jpg', '176_3.jpg', '150_0.jpg', '115_0.jpg', '47_0.jpg', '24_3.jpg', '61_3.jpg', '108_5.jpg', '108_4.jpg', '24_2.jpg', '61_2.jpg', '47_1.jpg', '150_1.jpg', '115_1.jpg', '133_2.jpg', '176_2.jpg', '189_0.jpg', '1_4.jpg', '169_5.jpg', '63_0.jpg', '194_5.jpg', '26_0.jpg', '45_3.jpg', '117_3.jpg', '152_3.jpg', '174_0.jpg', '83_5.jpg', '131_0.jpg', '78_3.jpg', '7_2.jpg', '149_0.jpg', '43_5.jpg', '192_3.jpg', '85_3.jpg', '111_5.jpg', '154_5.jpg', '19_2.jpg', '128_1.jpg', '5_0.jpg', '22_4.jpg', '190_1.jpg', '67_4.jpg', '135_4.jpg', '87_1.jpg', '170_4.jpg', '87_3.jpg', '113_5.jpg', '156_5.jpg', '41_5.jpg', '190_3.jpg', '128_3.jpg', '5_2.jpg', '19_0.jpg', '137_4.jpg', '85_1.jpg', '172_4.jpg', '20_4.jpg', '192_1.jpg', '65_4.jpg', '98_4.jpg', '149_2.jpg', '7_0.jpg', '78_1.jpg', '152_1.jpg', '117_1.jpg', '131_2.jpg', '174_2.jpg', '26_2.jpg', '63_2.jpg', '45_1.jpg', '189_2.jpg', '58_4.jpg', '115_3.jpg', '150_3.jpg', '176_0.jpg', '81_5.jpg', '133_0.jpg', '61_0.jpg', '196_5.jpg', '24_0.jpg', '47_3.jpg', '3_4.jpg', '39_5.jpg', '39_4.jpg', '3_5.jpg', '47_2.jpg', '61_1.jpg', '24_1.jpg', '196_4.jpg', '176_1.jpg', '133_1.jpg', '81_4.jpg', '115_2.jpg', '150_2.jpg', '58_5.jpg', '189_3.jpg', '45_0.jpg', '26_3.jpg', '63_3.jpg', '131_3.jpg', '174_3.jpg', '152_0.jpg', '117_0.jpg', '78_0.jpg', '149_3.jpg', '7_1.jpg', '98_5.jpg', '192_0.jpg', '20_5.jpg', '65_5.jpg', '85_0.jpg', '137_5.jpg', '172_5.jpg', '19_1.jpg', '5_3.jpg', '128_2.jpg', '190_2.jpg', '41_4.jpg', '113_4.jpg', '156_4.jpg', '87_2.jpg', '46_5.jpg', '197_3.jpg', '80_3.jpg', '151_5.jpg', '114_5.jpg', '38_3.jpg', '109_0.jpg', '2_2.jpg', '62_4.jpg', '195_1.jpg', '27_4.jpg', '175_4.jpg', '82_1.jpg', '130_4.jpg', '59_2.jpg', '188_4.jpg', '168_1.jpg', '0_0.jpg', '64_2.jpg', '21_2.jpg', '42_1.jpg', '110_1.jpg', '155_1.jpg', '173_2.jpg', '136_2.jpg', '148_4.jpg', '99_2.jpg', '23_0.jpg', '191_5.jpg', '66_0.jpg', '40_3.jpg', '157_3.jpg', '112_3.jpg', '134_0.jpg', '86_5.jpg', '171_0.jpg', '4_4.jpg', '129_5.jpg', '129_4.jpg', '4_5.jpg', '86_4.jpg', '134_1.jpg', '171_1.jpg', '157_2.jpg', '112_2.jpg', '40_2.jpg', '191_4.jpg', '23_1.jpg', '66_1.jpg', '99_3.jpg', '148_5.jpg', '173_3.jpg', '136_3.jpg', '110_0.jpg', '155_0.jpg', '42_0.jpg', '64_3.jpg', '21_3.jpg', '0_1.jpg', '168_0.jpg', '188_5.jpg', '59_3.jpg', '175_5.jpg', '130_5.jpg', '82_0.jpg', '62_5.jpg', '27_5.jpg', '195_0.jpg', '2_3.jpg', '109_1.jpg', '38_2.jpg', '151_4.jpg', '114_4.jpg', '80_2.jpg', '197_2.jpg', '46_4.jpg', '60_5.jpg', '25_5.jpg', '197_0.jpg', '177_5.jpg', '132_5.jpg', '80_0.jpg', '38_0.jpg', '109_3.jpg', '2_1.jpg', '195_2.jpg', '44_4.jpg', '153_4.jpg', '116_4.jpg', '82_2.jpg', '59_1.jpg', '0_3.jpg', '168_2.jpg', '42_2.jpg', '193_4.jpg', '21_1.jpg', '64_1.jpg', '84_4.jpg', '136_1.jpg', '173_1.jpg', '155_2.jpg', '110_2.jpg', '79_4.jpg', '99_1.jpg', '6_5.jpg', '40_0.jpg', '66_3.jpg', '23_3.jpg', '171_3.jpg', '134_3.jpg', '112_0.jpg', '157_0.jpg', '18_5.jpg', '18_4.jpg', '112_1.jpg', '157_1.jpg', '171_2.jpg', '134_2.jpg', '66_2.jpg', '23_2.jpg', '40_1.jpg', '6_4.jpg', '99_0.jpg', '79_5.jpg', '155_3.jpg', '110_3.jpg', '136_0.jpg', '84_5.jpg', '173_0.jpg', '21_0.jpg', '193_5.jpg', '64_0.jpg', '42_3.jpg', '168_3.jpg', '0_2.jpg', '59_0.jpg', '82_3.jpg', '153_5.jpg', '116_5.jpg', '44_5.jpg', '195_3.jpg', '2_0.jpg', '109_2.jpg', '38_1.jpg', '177_4.jpg', '80_1.jpg', '132_4.jpg', '60_4.jpg', '197_1.jpg', '25_4.jpg', '151_3.jpg', '114_3.jpg', '132_0.jpg', '80_5.jpg', '177_0.jpg', '25_0.jpg', '197_5.jpg', '60_0.jpg', '46_3.jpg', '2_4.jpg', '38_5.jpg', '116_1.jpg', '153_1.jpg', '175_2.jpg', '130_2.jpg', '62_2.jpg', '27_2.jpg', '44_1.jpg', '188_2.jpg', '59_4.jpg', '173_4.jpg', '84_1.jpg', '136_4.jpg', '64_4.jpg', '193_1.jpg', '21_4.jpg', '99_4.jpg', '6_0.jpg', '148_2.jpg', '79_1.jpg', '86_3.jpg', '157_5.jpg', '112_5.jpg', '40_5.jpg', '191_3.jpg', '129_3.jpg', '4_2.jpg', '18_0.jpg', '18_1.jpg', '4_3.jpg', '129_2.jpg', '191_2.jpg', '40_4.jpg', '157_4.jpg', '112_4.jpg', '86_2.jpg', '79_0.jpg', '6_1.jpg', '148_3.jpg', '99_5.jpg', '64_5.jpg', '21_5.jpg', '193_0.jpg', '173_5.jpg', '136_5.jpg', '84_0.jpg', '59_5.jpg', '188_3.jpg', '44_0.jpg', '62_3.jpg', '27_3.jpg', '175_3.jpg', '130_3.jpg', '116_0.jpg', '153_0.jpg', '38_4.jpg', '2_5.jpg', '46_2.jpg', '197_4.jpg', '25_1.jpg', '60_1.jpg', '80_4.jpg', '132_1.jpg', '177_1.jpg', '151_2.jpg', '114_2.jpg', '177_3.jpg', '132_3.jpg', '114_0.jpg', '151_0.jpg', '46_0.jpg', '60_3.jpg', '25_3.jpg', '109_5.jpg', '82_4.jpg', '130_1.jpg', '175_1.jpg', '153_2.jpg', '116_2.jpg', '44_2.jpg', '195_4.jpg', '27_1.jpg', '62_1.jpg', '168_4.jpg', '0_5.jpg', '188_1.jpg', '155_4.jpg', '110_4.jpg', '84_2.jpg', '193_2.jpg', '42_4.jpg', '148_1.jpg', '6_3.jpg', '79_2.jpg', '171_5.jpg', '134_5.jpg', '86_0.jpg', '66_5.jpg', '23_5.jpg', '191_0.jpg', '4_1.jpg', '129_0.jpg', '18_3.jpg', '18_2.jpg', '129_1.jpg', '4_0.jpg', '66_4.jpg', '191_1.jpg', '23_4.jpg', '171_4.jpg', '86_1.jpg', '134_4.jpg', '79_3.jpg', '148_0.jpg', '6_2.jpg', '42_5.jpg', '193_3.jpg', '84_3.jpg', '155_5.jpg', '110_5.jpg', '188_0.jpg', '0_4.jpg', '168_5.jpg', '27_0.jpg', '195_5.jpg', '62_0.jpg', '44_3.jpg', '153_3.jpg', '116_3.jpg', '130_0.jpg', '82_5.jpg', '175_0.jpg', '109_4.jpg', '60_2.jpg', '25_2.jpg', '46_1.jpg', '114_1.jpg', '151_1.jpg', '177_2.jpg', '132_2.jpg']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0_0.jpg', '0_1.jpg', '0_3.jpg', '0_2.jpg', '0_5.jpg', '0_4.jpg']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list = os.listdir('/Users/weduoo/Desktop/gugong/顾恺之洛神赋图卷（宋摹）/origin/')\n",
    "print(fnmatch.filter(list, '*.jpg'))\n",
    "fnmatch.filter(list, '0_*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[[[ 76, 203,  75, 109],\n",
    "         [ 10, 168, 225,  94],\n",
    "         [ 15,  37,   2,  45]],\n",
    "\n",
    "        [[ 79, 170, 132,  40],\n",
    "         [120, 181, 173, 183],\n",
    "         [184, 192,  71,  93]],\n",
    "\n",
    "        [[ 89, 119, 103, 195],\n",
    "         [224, 252,  16, 144],\n",
    "         [243, 254,  76,  28]]],\n",
    "\n",
    "\n",
    "       [[[220, 198, 184, 246],\n",
    "         [ 95, 230,  35,   4],\n",
    "         [225,  86, 206, 252]],\n",
    "\n",
    "        [[192,  71,  45, 100],\n",
    "         [  4,  99,  61, 244],\n",
    "         [ 94,  30,  68,   1]],\n",
    "\n",
    "        [[ 71,  39,   7,  13],\n",
    "         [120,  25, 241, 206],\n",
    "         [ 96,  66, 231,  55]]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([(1,2),(2,1),(0,5),(0,0)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "352px",
    "width": "366px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "252px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
