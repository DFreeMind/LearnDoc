{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error(误差)、Bias(偏差)、Variance(方差)\n",
    "**概念：训练误差（training error）、经验误差（empirical error）、泛化误差（generalization error）、拟合能力、稳定性、波动情况、数据充分性、偏差-方差窘境（bias-variance dilemma）、训练程度、欠拟合（underfitting）、过拟合（overfitting）**\n",
    "\n",
    "【参考】\n",
    "- [简书 - 总结：Bias(偏差)，Error(误差)，Variance(方差)及CV(交叉验证)](https://www.jianshu.com/p/8d01ac406b40)\n",
    "- [Understanding the Bias-Variance Tradeoff](http://scott.fortmann-roe.com/docs/BiasVariance.html) 有公式\n",
    "- [斯坦福机器学习笔记 - 偏差与方差](https://yoyoyohamapi.gitbooks.io/mit-ml/content/%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90%E4%B8%8E%E4%BC%98%E5%8C%96/articles/%E5%81%8F%E5%B7%AE%E4%B8%8E%E6%96%B9%E5%B7%AE.html)\n",
    "- [模型评估与选择 （ Bias(偏差)，Error(误差)，和Variance(方差) ）](https://blog.csdn.net/pacosonswjtu/article/details/59483747) 较全面"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一般地，通常会把模型输出和真实值之间的差异称为**误差（error）**。在训练集上的误差称为**训练误差（training error）**或者**经验误差（empirical error）**。而在新样本上的误差则称为**泛化误差（generalization error）**。\n",
    "\n",
    "机器学习中的泛化性能可以拆解为：$Err(x)=Bias^2+Variance+Noise$\n",
    "\n",
    "(1) Bias(偏差)  \n",
    "Bias反映的是模型在样本上的**输出与真实值**之间的**误差**，即模型本身的**精准度**，即算法本身的**拟合能力**。偏差越大，越偏离真实数据，如下图的第二行。\n",
    "\n",
    "(2) Variance(方差)  \n",
    "Variance反映的是模型每一次**输出结果与模型输出期望**之间的误差，即模型的**稳定性**，反应预测的**波动情况**（即使用同规模的不同训练集进行训练时带来的性能变化，刻画数据扰动带来的影响）。他描述了预测值的变化范围，离散程度，也就是离其期望值的距离。方差越大，数据的分布越分散，如下图的第二列。\n",
    "\n",
    "(3) Noise(噪音)  \n",
    "当前任务上任何算法所能达到的期望泛化误差的下界（即不可能有算法取得更小的误差），刻画**问题本身的难度**。即使数据集本身上的问题，不管你算法在怎么努力都不可能取得更小的误差，无论如何都不可能逾越过去，除非更换数据集。  \n",
    "就是不是你想要的真正数据，你可以想象为来破坏你实验的元凶和造成你可能过拟合的原因之一，至于为什么是过拟合的原因，因为模型过度追求Low Bias会导致训练过度，对测试集判断表现优秀，导致噪声点也被拟合进去了。\n",
    "\n",
    "也即是说，泛化性能包含了学习算法的拟合能力（偏差）、数据的充分性（方差）以及问题本身的难度（噪音）共同决定的。给定一个任务，噪声是固定的，我们需要做得就是尽量降低偏差和方差。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "偏差与方差的关系可以参考如下图：\n",
    "![image](https://wx3.sinaimg.cn/large/69d4185bly1fwj384opm5j20cl0ccmye.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "但是这两者其实是有冲突的，这称为**偏差-方差窘境（bias-variance dilemma）**。给定一个任务，我们可以控制算法的训练程度（如决策树的层数）。\n",
    "- 在训练程度较低时，拟合能力较差（欠拟合（underfitting）），因此训练数据的扰动不会让性能有显著变化，此时偏差主导泛化错误率；\n",
    "- 在训练程度较高时，拟合能力很强（过拟合（overfitting）），以至于训练数据自身的一些特性都会被拟合，从而产生过拟合问题，训练数据的轻微扰动都会令模型产生很大的变化，此时方差主导泛化错误率。\n",
    "\n",
    "需要注意的是，将泛化性能完美地分解为方差、偏差、噪声这三项仅在**基于均方误差的回归任务中**得以推导出，分类任务由于损失函数的跳变性导致难以从理论上推导出分解形式，但已经有很多方法可以通过实验进行估计了。\n",
    "\n",
    "通过诊断判断出现了高偏差或者高方差，我们就可以才去相应的处理方法：\n",
    "![image](https://wx2.sinaimg.cn/large/69d4185bly1fwj4oeg19xj20gd077my3.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据集：训练集、验证集、测试集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [sohu - 业界 | 似乎没区别，但你混淆过验证集和测试集吗？](http://www.sohu.com/a/159288970_465975)\n",
    "- [个站 - What is the Difference Between Test and Validation Datasets?](https://machinelearningmastery.com/difference-test-validation-datasets/) 上文的原文\n",
    "- [知乎 - 训练集(train)验证集(validation)测试集(test)与交叉验证法(Cross Validation)](https://zhuanlan.zhihu.com/p/35394638)\n",
    "- [交叉验证（简单交叉验证、k折交叉验证、留一法）](https://blog.csdn.net/u010451580/article/details/51373081)\n",
    "- [知乎 - 留一法交叉验证和普通交叉验证有什么区别？](https://www.zhihu.com/question/23561944)\n",
    "- [wikipedia - Training, validation, and test sets](https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通常情况下，「验证数据集」指模型训练过程中留出的样本集，可与「测试数据集」这个术语互换。\n",
    "\n",
    "- 训练集：用来学习的样本集，用于分类器参数的拟合。\n",
    "- 验证集：用来调整分类器超参数的样本集，如在神经网络中选择隐藏层神经元的数量。\n",
    "- 测试集：仅用于对已经训练好的分类器进行性能评估的样本集。\n",
    "\n",
    "**三者的区别**  \n",
    "形象上来说训练集就像是学生的课本，学生 根据课本里的内容来掌握知识，验证集就像是作业，通过作业可以知道 不同学生学习情况、进步的速度快慢，而最终的测试集就像是考试，考的题是平常都没有见过，考察学生举一反三的能力。\n",
    "\n",
    "**为什么要测试集**  \n",
    "训练集直接参与了模型调慘的过程，显然不能用来反映模型真实的能力，这样一些 对课本死记硬背的学生(过拟合)将会拥有最好的成绩，显然不对。同理，由于验证集参与了人工调参(超参数)的过程，也不能用来最终评判一个模型，就像刷题库的学生也不能算是学习好的学生是吧。所以要通过最终的考试(测试集)来考察一个学(模)生(型)真正的能力。\n",
    "\n",
    "但是仅凭一次考试就对模型的好坏进行评判显然是不合理的，所以就需要使用`交叉验证法`，交叉验证法的作用就是尝试利用不同的训练集/测试集划分来对模型做多组不同的训练/测试，来应对单次测试结果过于片面以及训练数据不足的问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 验证"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [sklearn - Cross-validation: evaluating estimator performance](https://scikit-learn.org/stable/modules/cross_validation.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- KFold\n",
    "![image](https://wx4.sinaimg.cn/large/69d4185bly1fxr64wrcqpj20fa07r0td.jpg)\n",
    "\n",
    "- 留一法(Leave One Out, LOO)\n",
    "- Leave P Out(LPO)\n",
    "- 随机排列交叉验证(Random permutations cross-validation a.k.a. Shuffle & Split)\n",
    "![image](https://wx1.sinaimg.cn/large/69d4185bly1fxrdwy4801j20fd07o3z8.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 分层 K-FLOD( Stratified k-fold)\n",
    "![image](https://ws4.sinaimg.cn/large/69d4185bly1fxre277skqj20fc07nmxu.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 分层混合分割(Stratified Shuffle Split)\n",
    "![image](https://wx2.sinaimg.cn/large/69d4185bly1fxre8zgvckj20f807ogme.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 分组 K-FLOD(Group k-fold)\n",
    "![image](https://ws2.sinaimg.cn/large/69d4185bly1fxremrxvcpj20fa07iq3l.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 留一组法(Leave One Group Out, LOGO)\n",
    "- 留 P 组(Leave P Groups Out, LPGO)\n",
    "- 分组混合分割(Group Shuffle Split)\n",
    "![image](https://wx2.sinaimg.cn/large/69d4185bly1fxrewscbozj20fa07jmxv.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 时序分割(Time series Split)\n",
    "![image](https://ws2.sinaimg.cn/large/69d4185bly1fxrf2c0x20j20fb07lt9b.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 评估"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **精确度(accuracy)**  \n",
    "\n",
    "- $y_i$ 第 $i$ 个样本的真是值\n",
    "- $\\hat{y}_i$ 第 $i$ 个样本的预测值\n",
    "- $n$ 样本的数量\n",
    "- $\\boldsymbol{1}(x)$ 指示函数，条件为真是值为1，否则为 0.\n",
    "\n",
    "$$\n",
    "\\large{\n",
    "\\begin{split}\n",
    "\\texttt{accuracy}(y, \\hat{y}) = \\frac{1}{n} \\sum_{i=0}^{n-1} \\boldsymbol{1}(\\hat{y}_i = y_i)\n",
    "\\end{split}\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **平衡精确度(balanced accuracy score)**\n",
    "\n",
    "- $y_i$ 第 $i$ 个样本的真是值\n",
    "- $\\hat{y}_i$ 第 $i$ 个样本的预测值\n",
    "- $\\boldsymbol{1}(x)$ 指示函数，条件为真是值为1，否则为 0.\n",
    "\n",
    "$$\n",
    "\\large{\n",
    "\\begin{split}\n",
    "\\texttt{balanced-accuracy}(y, \\hat{y}, \\omega) = \\frac{1}{\\sum{\\hat{\\omega}_i}} \\sum_i \\boldsymbol{1}(\\hat{y}_i = y_i) \\hat{\\omega}_i\n",
    "\\end{split}\n",
    "}\n",
    "$$\n",
    "\n",
    "其中 $\\hat{\\omega}_i$ 为：\n",
    "$$\n",
    "\\large{\n",
    "\\begin{split}\n",
    "\\hat{\\omega}_i = \\frac{\\omega_i}{\\sum_j{\\boldsymbol{1}(y_j = y_i) \\omega_j}}\n",
    "\\end{split}\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **混淆矩阵(confusion matrix)**\n",
    "对角线上的值越大越好，表明被预测正确的值越多。\n",
    "![image](https://wx1.sinaimg.cn/large/69d4185bly1fxsgoaz9doj20nb09st9p.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 查准率、查全率、F-score\n",
    "- tp: true positive, Correct result\n",
    "- fp: false positive, Unexpected result\n",
    "- fn: false negative, Missing result\n",
    "- tn: true negative, Correct absence of result\n",
    "\n",
    "**查准率(precision)**：预测为正例的样本中有多少真正例\n",
    "$$\n",
    "\\large{\n",
    "\\begin{split}\n",
    "\\text{precision} = \\frac{tp}{tp + fp}\n",
    "\\end{split}\n",
    "}\n",
    "$$\n",
    "**查全率(recall)**：正例样本中预测为正例的样本比例\n",
    "$$\n",
    "\\large{\n",
    "\\begin{split}\n",
    "\\text{recall} = \\frac{tp}{tp + fn}\n",
    "\\end{split}\n",
    "}\n",
    "$$\n",
    "\n",
    "**F score**：precision与 recall 的折中\n",
    "$$\n",
    "\\large{\n",
    "\\begin{split}\n",
    "F_\\beta = (1 + \\beta^2) \\frac{\\text{precision} \\times \\text{recall}}{\\beta^2 \\cdot \\text{precision} + \\text{recall}}\n",
    "\\end{split}\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多类别和多标签分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $y$： 预测 `(sample, label)` 对集合\n",
    "- $\\hat{y}$： 真实 `(sample, label)` 对集合\n",
    "- $L$：标签集合\n",
    "- $S$：样本集合\n",
    "- $y_s$：样本为 s 的 y 的子集，如 $y_s :=\\{(s',l) \\in y \\;|\\; s'=s\\}$\n",
    "- $y_l$：标签为 l 的 y 的子集\n",
    "- $\\hat{y}_s,\\hat{y}_l$与上面类似，是$\\hat{y}$ 的子集\n",
    "- $P(A,B):=\\frac{|A\\cap B|}{|A|}$\n",
    "- $R(A,B):=\\frac{|A\\cap B|}{|B|}$\n",
    "- $F_{\\beta}(A,B) = (1+\\beta^2)\\frac{P(A,B)\\times R(A,B)}{\\beta^2 \\cdot P(A,B) + R(A,B)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义如下的度量标准：\n",
    "![image](https://ws4.sinaimg.cn/large/69d4185bly1fxsr23d8kfj20p604tgmq.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 平均绝对值误差（L1）\n",
    "Mean absolute error（MAE）\n",
    "\n",
    "- $y_i$ 第 $i$ 个样本的真是值\n",
    "- $\\hat{y}_i$ 第 $i$ 个样本的预测值\n",
    "- $n$ 样本的数量\n",
    "\n",
    "$$\n",
    "\\large{\n",
    "\\begin{split}\n",
    "\\text{MAE}(y, \\hat{y}) = \\frac{1}{n} \\sum_{i=0}^{n-1} \\left| y_i - \\hat{y}_i \\right|\n",
    "\\end{split}\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 均方误差\n",
    "Mean squared error（MSE）\n",
    "\n",
    "- $y_i$ 第 $i$ 个样本的真是值\n",
    "- $\\hat{y}_i$ 第 $i$ 个样本的预测值\n",
    "- $n$ 样本的数量\n",
    "\n",
    "$$\n",
    "\\large{\n",
    "\\begin{split}\n",
    "\\text{MSE}(y, \\hat{y}) = \\frac{1}{n} \\sum_{i=0}^{n - 1} (y_i - \\hat{y}_i)^2\n",
    "\\end{split}\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 均方对数误差\n",
    "Mean squared logarithmic error（MSLE）\n",
    "\n",
    "- $y_i$ 第 $i$ 个样本的真是值\n",
    "- $\\hat{y}_i$ 第 $i$ 个样本的预测值\n",
    "- $n$ 样本的数量\n",
    "\n",
    "$$\n",
    "\\large{\n",
    "\\begin{split}\n",
    "\\text{MSLE}(y, \\hat{y}) = \\frac{1}{n} \\sum_{i=0}^{n - 1} \\left(\\log_e (1 + y_i) - \\log_e (1 + \\hat{y}_i) \\right)^2\n",
    "\\end{split}\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 中位数绝对值误差\n",
    "Median absolute error（MedAE），不支持多输出\n",
    "\n",
    "- $y_i$ 第 $i$ 个样本的真是值\n",
    "- $\\hat{y}_i$ 第 $i$ 个样本的预测值\n",
    "- $n$ 样本的数量\n",
    "\n",
    "$$\n",
    "\\large{\n",
    "\\begin{split}\n",
    "\\text{MedAE}(y, \\hat{y}) = \\text{median}(\\mid y_1 - \\hat{y}_1 \\mid, \\ldots, \\mid y_n - \\hat{y}_n \\mid)\n",
    "\\end{split}\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R2分数\n",
    "\n",
    "- $y_i$ 第 $i$ 个样本的真是值\n",
    "- $\\hat{y}_i$ 第 $i$ 个样本的预测值\n",
    "- $n$ 样本的数量\n",
    "\n",
    "$$\n",
    "\\large{\n",
    "\\begin{split}\n",
    "R^2(y, \\hat{y}) = 1 - \\frac{\\sum_{i=0}^{n - 1} (y_i - \\hat{y}_i)^2}{\\sum_{i=0}^{n - 1} (y_i - \\bar{y})^2},\\;\\;\\bar{y} = \\frac{1}{n} \\sum_{i=0}^{n - 1} y_i\n",
    "\\end{split}\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 其他"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 数据 Independent and Identically Distributed (i.i.d.)  假设"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "301px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
