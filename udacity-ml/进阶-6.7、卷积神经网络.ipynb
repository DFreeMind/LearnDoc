{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 卷积神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow 中实现卷积神经网络\n",
    "\n",
    "TensorFlow 提供了 `tf.nn.conv2d()` 和 `tf.nn.bias_add()` 函数来创建你自己的卷积层。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output depth\n",
    "k_output = 64\n",
    "\n",
    "# Image Properties\n",
    "image_width = 10\n",
    "image_height = 10\n",
    "color_channels = 3\n",
    "\n",
    "# Convolution filter\n",
    "filter_size_width = 5\n",
    "filter_size_height = 5\n",
    "\n",
    "# Input/Image\n",
    "input = tf.placeholder(\n",
    "    tf.float32,\n",
    "    shape=[None, image_height, image_width, color_channels])\n",
    "\n",
    "# Weight and bias\n",
    "weight = tf.Variable(tf.truncated_normal(\n",
    "    [filter_size_height, filter_size_width, color_channels, k_output]))\n",
    "bias = tf.Variable(tf.zeros(k_output))\n",
    "\n",
    "# Apply Convolution\n",
    "conv_layer = tf.nn.conv2d(input, weight, strides=[1, 2, 2, 1], padding='SAME')\n",
    "# Add bias\n",
    "conv_layer = tf.nn.bias_add(conv_layer, bias)\n",
    "# Apply activation function\n",
    "conv_layer = tf.nn.relu(conv_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上述代码用了 `tf.nn.conv2d()` 函数来计算卷积，weights 作为滤波器，`[1, 2, 2, 1]` 作为 strides。TensorFlow 对每一个 input 维度使用一个单独的 stride 参数，`[batch, input_height, input_width, input_channels]`。我们通常把 `batch` 和 `input_channels` （strides 序列中的第一个第四个）的 stride 设为 1。\n",
    "\n",
    "你可以专注于修改 `input_height` 和 `input_width`， `batch` 和 `input_channels` 都设置成 1。`input_height` 和 `input_width` strides 表示滤波器在input 上移动的步长。上述例子中，在 input 之后，设置了一个 5x5 ，stride 为 2 的滤波器。\n",
    "\n",
    "`tf.nn.bias_add()` 函数对矩阵的最后一维加了偏置项。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 最大池化操作\n",
    "![img](https://ws1.sinaimg.cn/large/69d4185bly1fpdb143kxoj20fu09674p.jpg)\n",
    "例如 `[[1, 0], [4, 6]]` 生成 6，因为 6 是这4个数字中最大的。同理 `[[2, 3], [6, 8]]` 生成 8。 理论上，最大池化操作的好处是减小输入大小，使得神经网络能够专注于最重要的元素。最大池化只取覆盖区域中的最大值，其它的值都丢弃。\n",
    "\n",
    "TensorFlow 提供了 `tf.nn.max_pool()` 函数，用于对卷积层实现 最大池化 。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer = tf.nn.conv2d(input, weight, strides=[1, 2, 2, 1], padding='SAME')\n",
    "conv_layer = tf.nn.bias_add(conv_layer, bias)\n",
    "conv_layer = tf.nn.relu(conv_layer)\n",
    "# Apply Max Pooling\n",
    "conv_layer = tf.nn.max_pool(\n",
    "    conv_layer,\n",
    "    ksize=[1, 2, 2, 1],\n",
    "    strides=[1, 2, 2, 1],\n",
    "    padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.nn.max_pool()` 函数实现最大池化时， `ksize`参数是滤波器大小，`strides`参数是步长。2x2 的滤波器配合 2x2 的步长是常用设定。\n",
    "\n",
    "ksize 和 strides 参数也被构建为四个元素的列表，每个元素对应 input tensor 的一个维度 (`[batch, height, width, channels]`)，对 ksize 和 strides 来说，batch 和 channel 通常都设置成 1。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow 中的卷积网络\n",
    "![img](https://ws1.sinaimg.cn/large/69d4185bly1fpdko13ps2g20em0aojsv.gif)\n",
    "这是一个 3x3 的卷积滤波器的示例。以 stride 为 1 应用到一个范围在 0 到 1 之间的数据上。每一个 3x3 的部分与权值 `[[1, 0, 1], [0, 1, 0], [1, 0, 1]]` 做卷积，把偏置加上后得到右边的卷积特征。这里偏置是 0 。TensorFlow 中这是通过 tf.nn.conv2d() 和 tf.nn.bias_add() 来完成的。\n",
    "```python\n",
    "def conv2d(x, W, b, strides=1):\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)\n",
    "```\n",
    "`tf.nn.conv2d()`函数与权值 W 做卷积。\n",
    "\n",
    "在 TensorFlow 中，strides 是一个4个元素的序列；第一个位置表示 stride 的 batch 参数，最后一个位置表示 stride 的特征(feature)参数。最好的移除 batch 和特征(feature)的方法是你直接在数据集中把他们忽略，而不是使用 stride。要使用所有的 batch 和特征(feature)，你可以把第一个和最后一个元素设成1。\n",
    "\n",
    "中间两个元素指纵向(height)和横向(width)的 stride，之前也提到过 stride 通常是正方形，height = width。当别人说 stride 是 3 的时候，他们意思是 `tf.nn.conv2d(x, W, strides=[1, 3, 3, 1])`。\n",
    "\n",
    "为了更简洁，这里的代码用了`tf.nn.bias_add()` 来添加偏置。 `tf.add()` 这里不能使用，因为 tensors 的维度不同。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting ./train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting ./train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting ./t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting ./t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\".\", one_hot=True, reshape=False)\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Parameters\n",
    "# 参数\n",
    "learning_rate = 0.00001\n",
    "epochs = 10\n",
    "batch_size = 128\n",
    "\n",
    "# Number of samples to calculate validation and accuracy\n",
    "# Decrease this if you're running out of memory to calculate accuracy\n",
    "# 用来验证和计算准确率的样本数\n",
    "# 如果内存不够，可以调小这个数字\n",
    "test_valid_size = 256\n",
    "\n",
    "# Network Parameters\n",
    "# 神经网络参数\n",
    "n_classes = 10  # MNIST total classes (0-9 digits)\n",
    "dropout = 0.75  # Dropout, probability to keep units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 权重与偏差项"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 32])),\n",
    "    'wc2': tf.Variable(tf.random_normal([5, 5, 32, 64])),\n",
    "    'wd1': tf.Variable(tf.random_normal([7*7*64, 1024])),\n",
    "    'out': tf.Variable(tf.random_normal([1024, n_classes]))}\n",
    "\n",
    "biases = {\n",
    "    'bc1': tf.Variable(tf.random_normal([32])),\n",
    "    'bc2': tf.Variable(tf.random_normal([64])),\n",
    "    'bd1': tf.Variable(tf.random_normal([1024])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 卷积"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x, W, b, strides=1):\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 最大池化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxpool2d(x, k=2):\n",
    "    return tf.nn.max_pool(\n",
    "        x,\n",
    "        ksize=[1, k, k, 1],\n",
    "        strides=[1, k, k, 1],\n",
    "        padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型\n",
    "![img](https://ws1.sinaimg.cn/large/69d4185bly1fpdkupfax5j220210g7wh.jpg)\n",
    "\n",
    "在下面的代码中，我们创建了 3 层来实现卷积，最大池化以及全链接层和输出层。每一层对维度的改变都写在注释里。例如第一层在卷积部分把图片从 28x28x1 变成了 28x28x32。后面应用了最大池化，每个样本变成了 14x14x32。从 conv1 经过多层网络，最后到 output 生成 10 个分类。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_net(x, weights, biases, dropout):\n",
    "    # Layer 1 - 28*28*1 to 14*14*32\n",
    "    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
    "    conv1 = maxpool2d(conv1, k=2)\n",
    "\n",
    "    # Layer 2 - 14*14*32 to 7*7*64\n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
    "    conv2 = maxpool2d(conv2, k=2)\n",
    "\n",
    "    # Fully connected layer - 7*7*64 to 1024\n",
    "    fc1 = tf.reshape(conv2, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    fc1 = tf.nn.dropout(fc1, dropout)\n",
    "\n",
    "    # Output Layer - class prediction - 1024 to 10\n",
    "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### session 中运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1, Batch   1 -Loss: 49498.5742 Validation Accuracy: 0.132812\n",
      "Epoch  1, Batch  21 -Loss: 15583.9990 Validation Accuracy: 0.355469\n",
      "Epoch  1, Batch  41 -Loss: 10467.6045 Validation Accuracy: 0.519531\n",
      "Epoch  1, Batch  61 -Loss:  6414.1133 Validation Accuracy: 0.601562\n",
      "Epoch  1, Batch  81 -Loss:  5401.9346 Validation Accuracy: 0.648438\n",
      "Epoch  1, Batch 101 -Loss:  3251.8738 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 121 -Loss:  3989.8267 Validation Accuracy: 0.675781\n",
      "Epoch  1, Batch 141 -Loss:  3241.5171 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 161 -Loss:  2244.8250 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 181 -Loss:  2963.5161 Validation Accuracy: 0.753906\n",
      "Epoch  1, Batch 201 -Loss:  3212.5054 Validation Accuracy: 0.769531\n",
      "Epoch  1, Batch 221 -Loss:  2921.8550 Validation Accuracy: 0.773438\n",
      "Epoch  1, Batch 241 -Loss:  1829.8149 Validation Accuracy: 0.761719\n",
      "Epoch  1, Batch 261 -Loss:  2413.0225 Validation Accuracy: 0.773438\n",
      "Epoch  1, Batch 281 -Loss:  2345.9712 Validation Accuracy: 0.773438\n",
      "Epoch  1, Batch 301 -Loss:  1284.1996 Validation Accuracy: 0.789062\n",
      "Epoch  1, Batch 321 -Loss:  1517.0281 Validation Accuracy: 0.792969\n",
      "Epoch  1, Batch 341 -Loss:  1285.4202 Validation Accuracy: 0.792969\n",
      "Epoch  1, Batch 361 -Loss:  1560.9751 Validation Accuracy: 0.804688\n",
      "Epoch  1, Batch 381 -Loss:   804.1479 Validation Accuracy: 0.800781\n",
      "Epoch  1, Batch 401 -Loss:  1947.7292 Validation Accuracy: 0.816406\n",
      "Epoch  1, Batch 421 -Loss:  2178.7319 Validation Accuracy: 0.812500\n",
      "Epoch  2, Batch   1 -Loss:  1569.1536 Validation Accuracy: 0.816406\n",
      "Epoch  2, Batch  21 -Loss:  1010.5574 Validation Accuracy: 0.816406\n",
      "Epoch  2, Batch  41 -Loss:  1531.7876 Validation Accuracy: 0.808594\n",
      "Epoch  2, Batch  61 -Loss:  1294.6664 Validation Accuracy: 0.820312\n",
      "Epoch  2, Batch  81 -Loss:  1865.9348 Validation Accuracy: 0.824219\n",
      "Epoch  2, Batch 101 -Loss:  1338.0103 Validation Accuracy: 0.824219\n",
      "Epoch  2, Batch 121 -Loss:  1794.1387 Validation Accuracy: 0.832031\n",
      "Epoch  2, Batch 141 -Loss:  1320.7244 Validation Accuracy: 0.828125\n",
      "Epoch  2, Batch 161 -Loss:  1248.3816 Validation Accuracy: 0.828125\n",
      "Epoch  2, Batch 181 -Loss:  1787.3635 Validation Accuracy: 0.828125\n",
      "Epoch  2, Batch 201 -Loss:   561.4949 Validation Accuracy: 0.828125\n",
      "Epoch  2, Batch 221 -Loss:  1266.4791 Validation Accuracy: 0.824219\n",
      "Epoch  2, Batch 241 -Loss:  1767.8047 Validation Accuracy: 0.828125\n",
      "Epoch  2, Batch 261 -Loss:  1134.1074 Validation Accuracy: 0.832031\n",
      "Epoch  2, Batch 281 -Loss:   999.9001 Validation Accuracy: 0.828125\n",
      "Epoch  2, Batch 301 -Loss:   767.7462 Validation Accuracy: 0.824219\n",
      "Epoch  2, Batch 321 -Loss:   778.7439 Validation Accuracy: 0.835938\n",
      "Epoch  2, Batch 341 -Loss:   699.3341 Validation Accuracy: 0.835938\n",
      "Epoch  2, Batch 361 -Loss:   780.4866 Validation Accuracy: 0.839844\n",
      "Epoch  2, Batch 381 -Loss:   565.7590 Validation Accuracy: 0.828125\n",
      "Epoch  2, Batch 401 -Loss:   929.3217 Validation Accuracy: 0.835938\n",
      "Epoch  2, Batch 421 -Loss:  1095.5415 Validation Accuracy: 0.832031\n",
      "Epoch  3, Batch   1 -Loss:   828.5308 Validation Accuracy: 0.835938\n",
      "Epoch  3, Batch  21 -Loss:  1132.1553 Validation Accuracy: 0.847656\n",
      "Epoch  3, Batch  41 -Loss:  1140.9480 Validation Accuracy: 0.855469\n",
      "Epoch  3, Batch  61 -Loss:  1295.8372 Validation Accuracy: 0.851562\n",
      "Epoch  3, Batch  81 -Loss:  1339.3484 Validation Accuracy: 0.843750\n",
      "Epoch  3, Batch 101 -Loss:   962.2416 Validation Accuracy: 0.847656\n",
      "Epoch  3, Batch 121 -Loss:  1100.5289 Validation Accuracy: 0.843750\n",
      "Epoch  3, Batch 141 -Loss:   882.3425 Validation Accuracy: 0.839844\n",
      "Epoch  3, Batch 161 -Loss:  1298.4602 Validation Accuracy: 0.839844\n",
      "Epoch  3, Batch 181 -Loss:   860.0461 Validation Accuracy: 0.847656\n",
      "Epoch  3, Batch 201 -Loss:  1235.4141 Validation Accuracy: 0.851562\n",
      "Epoch  3, Batch 221 -Loss:  1109.7216 Validation Accuracy: 0.847656\n",
      "Epoch  3, Batch 241 -Loss:   617.4874 Validation Accuracy: 0.855469\n",
      "Epoch  3, Batch 261 -Loss:   725.8138 Validation Accuracy: 0.851562\n",
      "Epoch  3, Batch 281 -Loss:   756.8414 Validation Accuracy: 0.855469\n",
      "Epoch  3, Batch 301 -Loss:   718.9106 Validation Accuracy: 0.859375\n",
      "Epoch  3, Batch 321 -Loss:   657.2293 Validation Accuracy: 0.859375\n",
      "Epoch  3, Batch 341 -Loss:   912.9433 Validation Accuracy: 0.859375\n",
      "Epoch  3, Batch 361 -Loss:   854.3719 Validation Accuracy: 0.863281\n",
      "Epoch  3, Batch 381 -Loss:   939.1038 Validation Accuracy: 0.859375\n",
      "Epoch  3, Batch 401 -Loss:  1115.6630 Validation Accuracy: 0.867188\n",
      "Epoch  3, Batch 421 -Loss:   735.3230 Validation Accuracy: 0.863281\n",
      "Epoch  4, Batch   1 -Loss:  1070.8934 Validation Accuracy: 0.855469\n",
      "Epoch  4, Batch  21 -Loss:   911.0838 Validation Accuracy: 0.867188\n",
      "Epoch  4, Batch  41 -Loss:  1052.3035 Validation Accuracy: 0.863281\n",
      "Epoch  4, Batch  61 -Loss:   760.0431 Validation Accuracy: 0.859375\n",
      "Epoch  4, Batch  81 -Loss:   650.7336 Validation Accuracy: 0.863281\n",
      "Epoch  4, Batch 101 -Loss:   829.4083 Validation Accuracy: 0.871094\n",
      "Epoch  4, Batch 121 -Loss:   734.7223 Validation Accuracy: 0.867188\n",
      "Epoch  4, Batch 141 -Loss:   582.7908 Validation Accuracy: 0.871094\n",
      "Epoch  4, Batch 161 -Loss:   991.6221 Validation Accuracy: 0.875000\n",
      "Epoch  4, Batch 181 -Loss:  1384.5848 Validation Accuracy: 0.863281\n",
      "Epoch  4, Batch 201 -Loss:   647.9667 Validation Accuracy: 0.871094\n",
      "Epoch  4, Batch 221 -Loss:   855.7516 Validation Accuracy: 0.871094\n",
      "Epoch  4, Batch 241 -Loss:   900.7332 Validation Accuracy: 0.871094\n",
      "Epoch  4, Batch 261 -Loss:   578.9388 Validation Accuracy: 0.867188\n",
      "Epoch  4, Batch 281 -Loss:   663.1737 Validation Accuracy: 0.875000\n",
      "Epoch  4, Batch 301 -Loss:   648.5731 Validation Accuracy: 0.867188\n",
      "Epoch  4, Batch 321 -Loss:   360.2166 Validation Accuracy: 0.863281\n",
      "Epoch  4, Batch 341 -Loss:   649.7057 Validation Accuracy: 0.863281\n",
      "Epoch  4, Batch 361 -Loss:   389.6501 Validation Accuracy: 0.855469\n",
      "Epoch  4, Batch 381 -Loss:   604.2064 Validation Accuracy: 0.859375\n",
      "Epoch  4, Batch 401 -Loss:   925.8759 Validation Accuracy: 0.867188\n",
      "Epoch  4, Batch 421 -Loss:   439.6733 Validation Accuracy: 0.871094\n",
      "Epoch  5, Batch   1 -Loss:   356.7716 Validation Accuracy: 0.871094\n",
      "Epoch  5, Batch  21 -Loss:   810.2256 Validation Accuracy: 0.867188\n",
      "Epoch  5, Batch  41 -Loss:   661.7168 Validation Accuracy: 0.875000\n",
      "Epoch  5, Batch  61 -Loss:   839.8016 Validation Accuracy: 0.878906\n",
      "Epoch  5, Batch  81 -Loss:   541.6125 Validation Accuracy: 0.875000\n",
      "Epoch  5, Batch 101 -Loss:   867.5322 Validation Accuracy: 0.875000\n",
      "Epoch  5, Batch 121 -Loss:   307.8393 Validation Accuracy: 0.875000\n",
      "Epoch  5, Batch 141 -Loss:   493.5514 Validation Accuracy: 0.871094\n",
      "Epoch  5, Batch 161 -Loss:   615.7306 Validation Accuracy: 0.875000\n",
      "Epoch  5, Batch 181 -Loss:   627.6852 Validation Accuracy: 0.867188\n",
      "Epoch  5, Batch 201 -Loss:   425.1395 Validation Accuracy: 0.867188\n",
      "Epoch  5, Batch 221 -Loss:   476.2417 Validation Accuracy: 0.867188\n",
      "Epoch  5, Batch 241 -Loss:   915.6668 Validation Accuracy: 0.871094\n",
      "Epoch  5, Batch 261 -Loss:   478.9530 Validation Accuracy: 0.863281\n",
      "Epoch  5, Batch 281 -Loss:   711.3440 Validation Accuracy: 0.871094\n",
      "Epoch  5, Batch 301 -Loss:   490.0191 Validation Accuracy: 0.863281\n",
      "Epoch  5, Batch 321 -Loss:   478.3623 Validation Accuracy: 0.871094\n",
      "Epoch  5, Batch 341 -Loss:   414.3741 Validation Accuracy: 0.863281\n",
      "Epoch  5, Batch 361 -Loss:   387.1487 Validation Accuracy: 0.871094\n",
      "Epoch  5, Batch 381 -Loss:   548.2861 Validation Accuracy: 0.871094\n",
      "Epoch  5, Batch 401 -Loss:   549.7723 Validation Accuracy: 0.871094\n",
      "Epoch  5, Batch 421 -Loss:   457.4128 Validation Accuracy: 0.867188\n",
      "Epoch  6, Batch   1 -Loss:   336.8926 Validation Accuracy: 0.871094\n",
      "Epoch  6, Batch  21 -Loss:   447.3453 Validation Accuracy: 0.875000\n",
      "Epoch  6, Batch  41 -Loss:   559.7484 Validation Accuracy: 0.875000\n",
      "Epoch  6, Batch  61 -Loss:   437.2303 Validation Accuracy: 0.875000\n",
      "Epoch  6, Batch  81 -Loss:   302.4116 Validation Accuracy: 0.875000\n",
      "Epoch  6, Batch 101 -Loss:   553.5281 Validation Accuracy: 0.878906\n",
      "Epoch  6, Batch 121 -Loss:   512.7080 Validation Accuracy: 0.875000\n",
      "Epoch  6, Batch 141 -Loss:   343.5009 Validation Accuracy: 0.875000\n",
      "Epoch  6, Batch 161 -Loss:   467.3170 Validation Accuracy: 0.871094\n",
      "Epoch  6, Batch 181 -Loss:   502.4275 Validation Accuracy: 0.871094\n",
      "Epoch  6, Batch 201 -Loss:   485.6497 Validation Accuracy: 0.867188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  6, Batch 221 -Loss:   448.0390 Validation Accuracy: 0.871094\n",
      "Epoch  6, Batch 241 -Loss:   456.3636 Validation Accuracy: 0.867188\n",
      "Epoch  6, Batch 261 -Loss:   429.1323 Validation Accuracy: 0.867188\n",
      "Epoch  6, Batch 281 -Loss:   479.3262 Validation Accuracy: 0.875000\n",
      "Epoch  6, Batch 301 -Loss:   462.2725 Validation Accuracy: 0.871094\n",
      "Epoch  6, Batch 321 -Loss:   591.1453 Validation Accuracy: 0.871094\n",
      "Epoch  6, Batch 341 -Loss:   580.1155 Validation Accuracy: 0.863281\n",
      "Epoch  6, Batch 361 -Loss:   632.9096 Validation Accuracy: 0.871094\n",
      "Epoch  6, Batch 381 -Loss:   550.5165 Validation Accuracy: 0.867188\n",
      "Epoch  6, Batch 401 -Loss:   664.2405 Validation Accuracy: 0.871094\n",
      "Epoch  6, Batch 421 -Loss:   557.3735 Validation Accuracy: 0.867188\n",
      "Epoch  7, Batch   1 -Loss:   601.0065 Validation Accuracy: 0.875000\n",
      "Epoch  7, Batch  21 -Loss:   518.1102 Validation Accuracy: 0.875000\n",
      "Epoch  7, Batch  41 -Loss:   390.7771 Validation Accuracy: 0.871094\n",
      "Epoch  7, Batch  61 -Loss:   555.6370 Validation Accuracy: 0.871094\n",
      "Epoch  7, Batch  81 -Loss:   401.6118 Validation Accuracy: 0.871094\n",
      "Epoch  7, Batch 101 -Loss:   419.7720 Validation Accuracy: 0.867188\n",
      "Epoch  7, Batch 121 -Loss:   427.7831 Validation Accuracy: 0.878906\n",
      "Epoch  7, Batch 141 -Loss:   354.9496 Validation Accuracy: 0.878906\n",
      "Epoch  7, Batch 161 -Loss:   563.4323 Validation Accuracy: 0.875000\n",
      "Epoch  7, Batch 181 -Loss:   581.8791 Validation Accuracy: 0.878906\n",
      "Epoch  7, Batch 201 -Loss:   340.4203 Validation Accuracy: 0.878906\n",
      "Epoch  7, Batch 221 -Loss:   569.0278 Validation Accuracy: 0.875000\n",
      "Epoch  7, Batch 241 -Loss:   509.4190 Validation Accuracy: 0.875000\n",
      "Epoch  7, Batch 261 -Loss:   451.5668 Validation Accuracy: 0.871094\n",
      "Epoch  7, Batch 281 -Loss:   674.0751 Validation Accuracy: 0.875000\n",
      "Epoch  7, Batch 301 -Loss:   686.9595 Validation Accuracy: 0.867188\n",
      "Epoch  7, Batch 321 -Loss:   347.3344 Validation Accuracy: 0.871094\n",
      "Epoch  7, Batch 341 -Loss:   618.0148 Validation Accuracy: 0.871094\n",
      "Epoch  7, Batch 361 -Loss:   227.5814 Validation Accuracy: 0.871094\n",
      "Epoch  7, Batch 381 -Loss:   366.3704 Validation Accuracy: 0.871094\n",
      "Epoch  7, Batch 401 -Loss:   393.5205 Validation Accuracy: 0.871094\n",
      "Epoch  7, Batch 421 -Loss:   416.3366 Validation Accuracy: 0.878906\n",
      "Epoch  8, Batch   1 -Loss:   498.1052 Validation Accuracy: 0.875000\n",
      "Epoch  8, Batch  21 -Loss:   536.9349 Validation Accuracy: 0.871094\n",
      "Epoch  8, Batch  41 -Loss:   101.2216 Validation Accuracy: 0.871094\n",
      "Epoch  8, Batch  61 -Loss:   253.7255 Validation Accuracy: 0.875000\n",
      "Epoch  8, Batch  81 -Loss:   391.2570 Validation Accuracy: 0.875000\n",
      "Epoch  8, Batch 101 -Loss:   472.0098 Validation Accuracy: 0.875000\n",
      "Epoch  8, Batch 121 -Loss:   375.3581 Validation Accuracy: 0.875000\n",
      "Epoch  8, Batch 141 -Loss:   477.4849 Validation Accuracy: 0.871094\n",
      "Epoch  8, Batch 161 -Loss:   275.7333 Validation Accuracy: 0.871094\n",
      "Epoch  8, Batch 181 -Loss:   487.9865 Validation Accuracy: 0.859375\n",
      "Epoch  8, Batch 201 -Loss:   289.0772 Validation Accuracy: 0.875000\n",
      "Epoch  8, Batch 221 -Loss:   365.3791 Validation Accuracy: 0.878906\n",
      "Epoch  8, Batch 241 -Loss:   405.3969 Validation Accuracy: 0.875000\n",
      "Epoch  8, Batch 261 -Loss:   360.1795 Validation Accuracy: 0.875000\n",
      "Epoch  8, Batch 281 -Loss:   245.2047 Validation Accuracy: 0.863281\n",
      "Epoch  8, Batch 301 -Loss:   432.3821 Validation Accuracy: 0.863281\n",
      "Epoch  8, Batch 321 -Loss:   542.3536 Validation Accuracy: 0.875000\n",
      "Epoch  8, Batch 341 -Loss:   226.8479 Validation Accuracy: 0.867188\n",
      "Epoch  8, Batch 361 -Loss:   238.3137 Validation Accuracy: 0.867188\n",
      "Epoch  8, Batch 381 -Loss:   371.9083 Validation Accuracy: 0.859375\n",
      "Epoch  8, Batch 401 -Loss:   450.2374 Validation Accuracy: 0.855469\n",
      "Epoch  8, Batch 421 -Loss:   190.3846 Validation Accuracy: 0.867188\n",
      "Epoch  9, Batch   1 -Loss:   338.2962 Validation Accuracy: 0.863281\n",
      "Epoch  9, Batch  21 -Loss:   534.3223 Validation Accuracy: 0.871094\n",
      "Epoch  9, Batch  41 -Loss:   450.9341 Validation Accuracy: 0.875000\n",
      "Epoch  9, Batch  61 -Loss:   631.0018 Validation Accuracy: 0.875000\n",
      "Epoch  9, Batch  81 -Loss:   542.3246 Validation Accuracy: 0.875000\n",
      "Epoch  9, Batch 101 -Loss:   277.5665 Validation Accuracy: 0.859375\n",
      "Epoch  9, Batch 121 -Loss:   401.8367 Validation Accuracy: 0.867188\n",
      "Epoch  9, Batch 141 -Loss:   300.2219 Validation Accuracy: 0.855469\n",
      "Epoch  9, Batch 161 -Loss:   313.6390 Validation Accuracy: 0.875000\n",
      "Epoch  9, Batch 181 -Loss:   364.1188 Validation Accuracy: 0.871094\n",
      "Epoch  9, Batch 201 -Loss:   457.0769 Validation Accuracy: 0.875000\n",
      "Epoch  9, Batch 221 -Loss:   236.5771 Validation Accuracy: 0.878906\n",
      "Epoch  9, Batch 241 -Loss:   273.9937 Validation Accuracy: 0.871094\n",
      "Epoch  9, Batch 261 -Loss:   349.0876 Validation Accuracy: 0.859375\n",
      "Epoch  9, Batch 281 -Loss:   301.8862 Validation Accuracy: 0.863281\n",
      "Epoch  9, Batch 301 -Loss:   245.0073 Validation Accuracy: 0.867188\n",
      "Epoch  9, Batch 321 -Loss:   172.7141 Validation Accuracy: 0.859375\n",
      "Epoch  9, Batch 341 -Loss:   464.3583 Validation Accuracy: 0.851562\n",
      "Epoch  9, Batch 361 -Loss:   418.3714 Validation Accuracy: 0.859375\n",
      "Epoch  9, Batch 381 -Loss:   292.9111 Validation Accuracy: 0.863281\n",
      "Epoch  9, Batch 401 -Loss:   118.0742 Validation Accuracy: 0.863281\n",
      "Epoch  9, Batch 421 -Loss:   368.2288 Validation Accuracy: 0.859375\n",
      "Epoch 10, Batch   1 -Loss:   347.5253 Validation Accuracy: 0.863281\n",
      "Epoch 10, Batch  21 -Loss:   275.4649 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch  41 -Loss:   207.2414 Validation Accuracy: 0.855469\n",
      "Epoch 10, Batch  61 -Loss:   589.5397 Validation Accuracy: 0.863281\n",
      "Epoch 10, Batch  81 -Loss:   203.9701 Validation Accuracy: 0.867188\n",
      "Epoch 10, Batch 101 -Loss:   225.2828 Validation Accuracy: 0.863281\n",
      "Epoch 10, Batch 121 -Loss:   254.0830 Validation Accuracy: 0.859375\n",
      "Epoch 10, Batch 141 -Loss:   142.4740 Validation Accuracy: 0.863281\n",
      "Epoch 10, Batch 161 -Loss:   561.0276 Validation Accuracy: 0.863281\n",
      "Epoch 10, Batch 181 -Loss:   210.7463 Validation Accuracy: 0.859375\n",
      "Epoch 10, Batch 201 -Loss:   291.2986 Validation Accuracy: 0.863281\n",
      "Epoch 10, Batch 221 -Loss:   243.7617 Validation Accuracy: 0.859375\n",
      "Epoch 10, Batch 241 -Loss:   385.3571 Validation Accuracy: 0.871094\n",
      "Epoch 10, Batch 261 -Loss:   303.9064 Validation Accuracy: 0.875000\n",
      "Epoch 10, Batch 281 -Loss:   401.0591 Validation Accuracy: 0.863281\n",
      "Epoch 10, Batch 301 -Loss:   168.2458 Validation Accuracy: 0.867188\n",
      "Epoch 10, Batch 321 -Loss:   312.3215 Validation Accuracy: 0.863281\n",
      "Epoch 10, Batch 341 -Loss:   396.7840 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 361 -Loss:   254.9113 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 381 -Loss:   254.8692 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 401 -Loss:   182.1127 Validation Accuracy: 0.851562\n",
      "Epoch 10, Batch 421 -Loss:   375.9512 Validation Accuracy: 0.851562\n",
      "Testing Accuracy: 0.8671875\n"
     ]
    }
   ],
   "source": [
    "# tf Graph input\n",
    "x = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, weights, biases, keep_prob)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(\\\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\\\n",
    "    .minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf. global_variables_initializer()\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for batch in range(mnist.train.num_examples//batch_size):\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            sess.run(optimizer, feed_dict={\n",
    "                x: batch_x,\n",
    "                y: batch_y,\n",
    "                keep_prob: dropout})\n",
    "\n",
    "            # Calculate batch loss and accuracy\n",
    "            loss = sess.run(cost, feed_dict={\n",
    "                x: batch_x,\n",
    "                y: batch_y,\n",
    "                keep_prob: 1.})\n",
    "            valid_acc = sess.run(accuracy, feed_dict={\n",
    "                x: mnist.validation.images[:test_valid_size],\n",
    "                y: mnist.validation.labels[:test_valid_size],\n",
    "                keep_prob: 1.})\n",
    "            if batch % 20 == 0:\n",
    "                print('Epoch {:>2}, Batch {:>3} -'\n",
    "                      'Loss: {:>10.4f} Validation Accuracy: {:.6f}'.format(\n",
    "                    epoch + 1,\n",
    "                    batch + 1,\n",
    "                    loss,\n",
    "                    valid_acc))\n",
    "\n",
    "    # Calculate Test Accuracy\n",
    "    test_acc = sess.run(accuracy, feed_dict={\n",
    "        x: mnist.test.images[:test_valid_size],\n",
    "        y: mnist.test.labels[:test_valid_size],\n",
    "        keep_prob: 1.})\n",
    "    print('Testing Accuracy: {}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
