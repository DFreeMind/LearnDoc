{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基础"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据类型\n",
    "### 常量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'hello', 123.45]\n",
      "[1 2 3 4 5]\n",
      "[[1 2 3]\n",
      " [4 5 5]]\n",
      "[[1 1]\n",
      " [1 1]]\n"
     ]
    }
   ],
   "source": [
    "# 常量（一旦赋值不可更改）\n",
    "hello_const = tf.constant(\"hello\")\n",
    "int_const = tf.constant(123.45)\n",
    "array_const = tf.constant([1,2,3,4,5])\n",
    "# 改变数据形状\n",
    "d_const = tf.constant([1,2,3,4,5],shape=(2,3))\n",
    "d2_const = tf.constant(1,shape=(2,2))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    output = sess.run([hello_const,int_const])\n",
    "    print(output)\n",
    "    output = sess.run(array_const)\n",
    "    print(output)\n",
    "    output = sess.run(d_const)\n",
    "    print(output)\n",
    "    output = sess.run(d2_const)\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123\n",
      "234\n"
     ]
    }
   ],
   "source": [
    "# 可赋值量（一旦赋值不可更改）\n",
    "# 设置变量的数据类型\n",
    "x = tf.placeholder(tf.int32)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # 使用 feed_dict 为变量赋值\n",
    "    output =  sess.run(x,feed_dict={x:123})\n",
    "    print(output)\n",
    "    # 相同的 key ，后面的值会覆盖前面的\n",
    "    output =  sess.run(x,feed_dict={x:123,x:234})\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'helo'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-49da7f34603b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# 相同的 key ，后面的值会覆盖前面的\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"helo\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1095\u001b[0m             \u001b[0mfeed_handles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubfeed_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1097\u001b[0;31m             \u001b[0mnp_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubfeed_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m           if (not is_tensor_handle_feed and\n",
      "\u001b[0;32m/anaconda3/envs/py36/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \"\"\"\n\u001b[0;32m--> 531\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'helo'"
     ]
    }
   ],
   "source": [
    "# 变量类型要一直不一致会报错\n",
    "y = tf.placeholder(tf.string)\n",
    "z = tf.placeholder(tf.float32)\n",
    "x = tf.placeholder(tf.float32,[None,2])\n",
    "with tf.Session() as sess:\n",
    "    # 使用 feed_dict 为变量赋值\n",
    "    output =  sess.run(y,feed_dict={y:\"123\"})\n",
    "    print(output)\n",
    "    # 相同的 key ，后面的值会覆盖前面的\n",
    "    output =  sess.run(z,feed_dict={z:\"helo\"})\n",
    "    print(output)\n",
    "    x = tf.placeholder(tf.float32,[None,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1]\n",
      " [2 3]\n",
      " [4 5]\n",
      " [6 7]]\n",
      "[[0 1]\n",
      " [2 3]]\n",
      "[[0 1 2 3]\n",
      " [4 5 6 7]]\n",
      "[[0 1 2]\n",
      " [3 4 5]]\n"
     ]
    }
   ],
   "source": [
    "# 输入数据的形状，如果不设置 shape，可以接受任何形状的数据\n",
    "# 设置了 shape 之后则接受固定形状的数据，如：\n",
    "# [None,2]：只接受列数为2的数据\n",
    "# [2,None]：只接受行数为2的数据\n",
    "x = tf.placeholder(tf.int32,[None,2])\n",
    "y = tf.placeholder(tf.int32,[2,None])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # 两列\n",
    "    output =  sess.run(x,feed_dict={x:np.array([i for i in range(8)]).reshape(4,2)})\n",
    "    print(output)\n",
    "    output =  sess.run(x,feed_dict={x:np.array([i for i in range(4)]).reshape(2,2)})\n",
    "    print(output)\n",
    "    # 两行\n",
    "    output =  sess.run(y,feed_dict={y:np.array([i for i in range(8)]).reshape(2,4)})\n",
    "    print(output)\n",
    "    output =  sess.run(y,feed_dict={y:np.array([i for i in range(6)]).reshape(2,3)})\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 变量\n",
    "使用[`tf.Variable()`](https://www.tensorflow.org/api_docs/python/tf/Variable)创建一个 tensor 变量，该 tensor 把她的状态存储在 session 里面，需要手动初始化她的状态。可以使用[`tf.global_variables_initializer()`](https://www.tensorflow.org/api_docs/python/tf/global_variables_initializer) 来初始化所有的可变 tensor。\n",
    "\n",
    "在神经你网络中经常使用正态分布来初始化变量，在 TensorFlow 中可以使用 [`tf.truncated_normal()`](https://www.tensorflow.org/versions/r1.8/api_docs/python/tf/truncated_normal)，该方法返回一个 tensor，取值在两个标准差之间。\n",
    "\n",
    "[`tf.zeros()`](https://www.tensorflow.org/versions/master/api_docs/python/tf/zeros)返回都是零的 tensor。\n",
    "\n",
    "[`tf.matul()`](https://www.tensorflow.org/versions/master/api_docs/python/tf/matmul) 用于计算矩阵的乘法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "# 创建变量\n",
    "x = tf.Variable(5)\n",
    "#初始化所有变量\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    # 进行初始化\n",
    "    sess.run(init)\n",
    "    print(sess.run(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.48473635 -0.05133247  1.55402684]\n",
      " [ 0.16736767  0.25429818 -0.19968075]\n",
      " [-1.32056379  0.5557735  -0.28035232]]\n",
      "[[ 0.  0.  0.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "# 正态分布\n",
    "n_features = 3\n",
    "n_labels = 3\n",
    "weights = tf.Variable(tf.truncated_normal((n_features,n_labels)))\n",
    "zeros = tf.Variable(tf.zeros((n_features,n_labels),tf.float32))\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    # 进行初始化\n",
    "    sess.run(init)\n",
    "    print(sess.run(weights))\n",
    "    print(sess.run(zeros))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 2]\n",
      " [3 4 5]\n",
      " [6 7 8]]\n",
      "[[0 1]\n",
      " [2 3]\n",
      " [4 5]]\n",
      "[[10 13]\n",
      " [28 40]\n",
      " [46 67]]\n"
     ]
    }
   ],
   "source": [
    "# 矩阵乘法\n",
    "d2_array = tf.constant([i for i in range(9)],shape=(3,3))\n",
    "d3_array = tf.constant([i for i in range(6)],shape=(3,2))\n",
    "output = tf.matmul(d2_array,d3_array)\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(d2_array))\n",
    "    print(sess.run(d3_array))\n",
    "    print(sess.run(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基础运算\n",
    "进行运算时数据的类型要一致，不一致会发生错误。可以使用`tf.cast()`将数据转成一致的类型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "4\n",
      "10\n",
      "1\n",
      "3.33333333333\n"
     ]
    }
   ],
   "source": [
    "# 加\n",
    "x = tf.add(1,2)\n",
    "y = tf.subtract(10,6)\n",
    "z = tf.multiply(2,5)\n",
    "u = tf.subtract(tf.cast(tf.constant(2.0),tf.int32),1)\n",
    "v = tf.divide(tf.constant(10),tf.constant(3))\n",
    "# 不适用内部的常量会报错\n",
    "w = tf.divide(10,3)\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(x))\n",
    "    print(sess.run(y))\n",
    "    print(sess.run(z))\n",
    "    print(sess.run(u))\n",
    "    print(sess.run(v))\n",
    "#     print(sess.run(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 逐级运算\n",
    "常见的逐级运算有：\n",
    "- [`tf.reduce_mean()`](https://www.tensorflow.org/versions/master/api_docs/python/tf/reduce_mean)：对元素求平均"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "[2 3 4]\n",
      "[2 5]\n"
     ]
    }
   ],
   "source": [
    "#求平均（注意整数求平均）\n",
    "x = tf.reduce_mean([[1,2,3],[4,5,6]])\n",
    "# 按列求平均\n",
    "y = tf.reduce_mean([[1,2,3],[4,5,6]],axis=0)\n",
    "# 按行求平均\n",
    "z = tf.reduce_mean([[1,2,3],[4,5,6]],axis=1)\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(x))\n",
    "    print(sess.run(y))\n",
    "    print(sess.run(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 正态分布\n",
    "正态分布式使用[`tf.truncated_normal()`](https://www.tensorflow.org/versions/master/api_docs/python/tf/truncated_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sess_constant_print(params):\n",
    "    with tf.Session() as sess:\n",
    "        for i in params:\n",
    "            print(sess.run(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.20156288  0.90780312  0.85587955]\n",
      " [-0.37296245  0.40275913 -0.35058528]]\n"
     ]
    }
   ],
   "source": [
    "x = tf.truncated_normal(shape=(2,3))\n",
    "sess_constant_print([x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 常用函数\n",
    "## NN 中常用函数\n",
    "### softmax 函数\n",
    "使用教程可查看 [`tf.nn.softmax()`](https://www.tensorflow.org/versions/master/api_docs/python/tf/nn/softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.65900117  0.24243298  0.09856589]\n"
     ]
    }
   ],
   "source": [
    "logit_data = [2.0, 1.0, 0.1]\n",
    "logits = tf.placeholder(tf.float32)\n",
    "softmax = tf.nn.softmax(logits)\n",
    "with tf.Session() as sess:\n",
    "    output = sess.run(softmax,feed_dict={logits:logit_data})\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 交叉熵函数(Cross Entropy)\n",
    "会使用到 [`tf.reduce_sum()`](https://www.tensorflow.org/versions/master/api_docs/python/tf/reduce_sum)、[`tf.log()`](https://www.tensorflow.org/versions/master/api_docs/python/tf/log) 两个函数。\n",
    "\n",
    "交叉熵的公式如下：$$D(\\widehat y ,y) = - \\sum_{j}y_jln\\widehat y_j$$\n",
    "\n",
    "或者使用 TensorFlow 提供的交叉函数计算方法，[`tf.nn.softmax_cross_entropy_with_logits_v2()`](https://www.tensorflow.org/versions/master/api_docs/python/tf/nn/softmax_cross_entropy_with_logits_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "# 逐个求和\n",
    "x = tf.reduce_sum([1,2,3,4,5])\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.60517025  5.29831743]\n"
     ]
    }
   ],
   "source": [
    "# 自然对数，值的类型必须是float16, bfloat16, float32, float64, complex64, complex128\n",
    "x = tf.log([100.0,200.0])\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.356675\n",
      "0.76795\n"
     ]
    }
   ],
   "source": [
    "# 计算交叉熵\n",
    "# 预测值\n",
    "softmax_data = [0.7, 0.2, 0.1]\n",
    "# 真实值\n",
    "one_hot_data = [1.0, 0.0, 0.0]\n",
    "\n",
    "softmax = tf.placeholder(tf.float32)\n",
    "one_hot = tf.placeholder(tf.float32)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    ce = -tf.reduce_sum(one_hot * tf.log(softmax))\n",
    "    output = sess.run(ce, feed_dict={one_hot:one_hot_data, softmax:softmax_data})\n",
    "    print(output)\n",
    "    sf = tf.nn.softmax_cross_entropy_with_logits_v2(logits = softmax_data, labels= one_hot_data)\n",
    "    print(sess.run(sf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mini-batching 使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# None 用于接受 batch 的值,[None,_] 表示数据的形状\n",
    "features = tf.placeholder(tf.float32, [None, n_input])\n",
    "labels = tf.placeholder(tf.float32, [None, labels])\n",
    "\n",
    "example_features = [\n",
    "    ['F11','F12','F13','F14'],\n",
    "    ['F21','F22','F23','F24'],\n",
    "    ['F31','F32','F33','F34'],\n",
    "    ['F41','F42','F43','F44']]\n",
    "# 4 个 label\n",
    "example_labels = [\n",
    "    ['L11','L12'],\n",
    "    ['L21','L22'],\n",
    "    ['L31','L32'],\n",
    "    ['L41','L42']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 优化函数\n",
    "1. **梯度下降优化函数**\n",
    "\n",
    "[`tf.train.GradientDescentOptimizer()`](https://www.tensorflow.org/versions/master/api_docs/python/tf/train/GradientDescentOptimizer) 参数为学习速率，接着使用 `minimize()` 方法来优化损失函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型保存与读取\n",
    "保存模型使用[`tf.train.Saver()`](https://www.tensorflow.org/versions/master/api_docs/python/tf/train/Saver), 之后使用`save()`来保存变量，`restore()`用于读取模型。\n",
    "\n",
    "为了能让 TensorFlow 正确的读取模型，需要为变量设置真给的名称，不要让 TensorFlow 自己设置，否则会报分配错误。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights: [[ 0.64105231  1.04426181  1.74303126]\n",
      " [-1.00506294 -1.38636625 -1.26485753]]\n",
      "bias: [ 0.4997752   0.52395737  1.78492796]\n"
     ]
    }
   ],
   "source": [
    "# 保存变量\n",
    "model_path = \"./datafile/tensorflow/weights_bias.ckpt\"\n",
    "weights = tf.Variable(tf.truncated_normal([2,3]), name=\"weights\")\n",
    "bias = tf.Variable(tf.truncated_normal(shape=[3]), name=\"bias\")\n",
    "\n",
    "# 创建用于保存变量的 tensor\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # 初始化变量\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # 打印权重变量\n",
    "    print(\"weights:\",sess.run(weights))\n",
    "    print(\"bias:\",sess.run(bias))\n",
    "    \n",
    "    # 保存变量\n",
    "    saver.save(sess, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./datafile/tensorflow/weights_bias.ckpt\n",
      "weights: [[-0.76870435  0.14591242 -1.51366234]\n",
      " [-0.29159763 -1.41122425 -0.57689452]]\n",
      "bias: [ 0.4997752   0.52395737  1.78492796]\n"
     ]
    }
   ],
   "source": [
    "# 读取模型变量\n",
    "# 移除之前的权重与偏置项\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# 创建变量\n",
    "weights = tf.Variable(tf.truncated_normal([2,3]), name=\"weights\")\n",
    "bias = tf.Variable(tf.truncated_normal(shape=[3]), name=\"bias\")\n",
    "\n",
    "# 用于读取模型\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    # 加载偏置项\n",
    "    saver.restore(sess, model_path)\n",
    "    # 打印权重变量\n",
    "    print(\"weights:\",sess.run(weights))\n",
    "    print(\"bias:\",sess.run(bias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
